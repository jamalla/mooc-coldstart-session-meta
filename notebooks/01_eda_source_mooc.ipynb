{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8996ee83",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "120ad813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 01-01] Imports (UPDATED for raw XuetangX JSON -> Parquet -> DuckDB)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import yaml\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except Exception as e:\n",
    "    pd = None\n",
    "    print(\"⚠️ pandas not available:\", e)\n",
    "\n",
    "def log(msg: str):\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[01] {ts} | {msg}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e728a8",
   "metadata": {},
   "source": [
    "Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2d67993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] 2025-12-28 23:10:27 | Initial CWD: D:\\00_DS-ML-Workspace\\mooc-coldstart-session-meta\n",
      "[01] 2025-12-28 23:10:27 | Detected REPO_ROOT: D:\\00_DS-ML-Workspace\\mooc-coldstart-session-meta\n",
      "[01] 2025-12-28 23:10:27 | CWD now: D:\\00_DS-ML-Workspace\\mooc-coldstart-session-meta\n",
      "[01] 2025-12-28 23:10:27 | Validation checks:\n",
      "  ✅ src/\n",
      "  ✅ notebooks/\n",
      "  ✅ PROJECT_STATE.md\n",
      "  ✅ src/configs/project.yaml\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-02] Bootstrap: locate repo root reliably (Windows-safe)\n",
    "\n",
    "CWD = Path.cwd().resolve()\n",
    "log(f\"Initial CWD: {CWD}\")\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Search upward for repo root.\n",
    "    Priority: PROJECT_STATE.md (most specific).\n",
    "    Fallback: .git folder.\n",
    "    \"\"\"\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / \"PROJECT_STATE.md\").exists():\n",
    "            return p.resolve()\n",
    "\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / \".git\").exists():\n",
    "            return p.resolve()\n",
    "\n",
    "    # Last resort: don't guess; just use current folder\n",
    "    return start.resolve()\n",
    "\n",
    "REPO_ROOT = find_repo_root(CWD)\n",
    "log(f\"Detected REPO_ROOT: {REPO_ROOT}\")\n",
    "\n",
    "# Move execution context to repo root (so relative paths behave consistently)\n",
    "os.chdir(REPO_ROOT)\n",
    "log(f\"CWD now: {Path.cwd().resolve()}\")\n",
    "\n",
    "# Add repo root + src to import path\n",
    "SRC_DIR = REPO_ROOT / \"src\"\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "if SRC_DIR.exists() and str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "# Validation checks\n",
    "checks = {\n",
    "    \"src/\": (REPO_ROOT / \"src\").exists(),\n",
    "    \"notebooks/\": (REPO_ROOT / \"notebooks\").exists(),\n",
    "    \"PROJECT_STATE.md\": (REPO_ROOT / \"PROJECT_STATE.md\").exists(),\n",
    "    \"src/configs/project.yaml\": (REPO_ROOT / \"src\" / \"configs\" / \"project.yaml\").exists(),\n",
    "}\n",
    "\n",
    "log(\"Validation checks:\")\n",
    "for name, exists in checks.items():\n",
    "    status = \"✅\" if exists else \"❌\"\n",
    "    print(f\"  {status} {name}\")\n",
    "\n",
    "if not checks[\"PROJECT_STATE.md\"]:\n",
    "    raise FileNotFoundError(\"PROJECT_STATE.md not found in detected repo root — wrong working directory?\")\n",
    "\n",
    "if not checks[\"src/configs/project.yaml\"]:\n",
    "    raise FileNotFoundError(\"src/configs/project.yaml not found — please ensure the config exists.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d3e670",
   "metadata": {},
   "source": [
    "Config loader (src/configs/project.yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a69d97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] 2025-12-28 23:10:41 | Loading config: D:\\00_DS-ML-Workspace\\mooc-coldstart-session-meta\\src\\configs\\project.yaml\n",
      "[01] 2025-12-28 23:10:41 | Config loaded.\n",
      "[01] 2025-12-28 23:10:41 | Top-level keys: ['paths', 'project', 'repro', 'training']\n",
      "[01] 2025-12-28 23:10:41 | RAW_DIR from config: data/raw  ->  D:\\00_DS-ML-Workspace\\mooc-coldstart-session-meta\\data\\raw\n",
      "[01] 2025-12-28 23:10:41 | RAW_DIR exists: True\n",
      "[01] 2025-12-28 23:10:41 | ℹ️ No explicit source dataset subdir found in config (that’s okay).\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-03] Load project config (YAML) \n",
    "\n",
    "CFG_PATH = REPO_ROOT / \"src\" / \"configs\" / \"project.yaml\"\n",
    "log(f\"Loading config: {CFG_PATH}\")\n",
    "\n",
    "with open(CFG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    CFG = yaml.safe_load(f) or {}\n",
    "\n",
    "log(\"Config loaded.\")\n",
    "log(f\"Top-level keys: {sorted(list(CFG.keys()))}\")\n",
    "\n",
    "def cfg_get(*path, default=None):\n",
    "    \"\"\"\n",
    "    Safe nested getter: cfg_get('data','raw_dir')\n",
    "    \"\"\"\n",
    "    cur = CFG\n",
    "    for k in path:\n",
    "        if not isinstance(cur, dict) or k not in cur:\n",
    "            return default\n",
    "        cur = cur[k]\n",
    "    return cur\n",
    "\n",
    "# Try common conventions without assuming which one you used\n",
    "RAW_DIR_CANDIDATES = [\n",
    "    cfg_get(\"paths\", \"raw_dir\"),\n",
    "    cfg_get(\"data\", \"raw_dir\"),\n",
    "    cfg_get(\"data\", \"raw\"),\n",
    "    cfg_get(\"paths\", \"data_raw\"),\n",
    "]\n",
    "\n",
    "RAW_DIR_VALUE = next((x for x in RAW_DIR_CANDIDATES if isinstance(x, str) and x.strip()), None)\n",
    "\n",
    "if RAW_DIR_VALUE is None:\n",
    "    log(\"⚠️ Could not find raw dir in config using common keys.\")\n",
    "    log(\"Searched keys: paths.raw_dir, data.raw_dir, data.raw, paths.data_raw\")\n",
    "    RAW_DIR = None\n",
    "else:\n",
    "    RAW_DIR = (REPO_ROOT / RAW_DIR_VALUE).resolve()\n",
    "    log(f\"RAW_DIR from config: {RAW_DIR_VALUE}  ->  {RAW_DIR}\")\n",
    "    log(f\"RAW_DIR exists: {RAW_DIR.exists()}\")\n",
    "\n",
    "# Try common conventions for \"source dataset subdir\"\n",
    "SOURCE_SUBDIR_CANDIDATES = [\n",
    "    cfg_get(\"datasets\", \"source_mooc\", \"subdir\"),\n",
    "    cfg_get(\"datasets\", \"source\", \"subdir\"),\n",
    "    cfg_get(\"data\", \"source_mooc_subdir\"),\n",
    "    cfg_get(\"source_dataset\", \"subdir\"),\n",
    "]\n",
    "\n",
    "SOURCE_SUBDIR = next((x for x in SOURCE_SUBDIR_CANDIDATES if isinstance(x, str) and x.strip()), None)\n",
    "if SOURCE_SUBDIR is None:\n",
    "    log(\"ℹ️ No explicit source dataset subdir found in config (that’s okay).\")\n",
    "    SOURCE_DIR = None if RAW_DIR is None else RAW_DIR\n",
    "else:\n",
    "    SOURCE_DIR = None if RAW_DIR is None else (RAW_DIR / SOURCE_SUBDIR).resolve()\n",
    "    log(f\"SOURCE_SUBDIR from config: {SOURCE_SUBDIR}\")\n",
    "    log(f\"SOURCE_DIR resolved: {SOURCE_DIR}\")\n",
    "    log(f\"SOURCE_DIR exists: {SOURCE_DIR.exists()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a125a43",
   "metadata": {},
   "source": [
    "data/raw inventory + file-size summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3122d3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] 2025-12-28 23:11:47 | Scanning RAW_DIR: D:\\00_DS-ML-Workspace\\mooc-coldstart-session-meta\\data\\raw\n",
      "[01] 2025-12-28 23:11:47 | Found files: 11\n",
      "[01] 2025-12-28 23:11:47 | Total size: 29.46 GB\n",
      "[01] 2025-12-28 23:11:47 | Top-level subdirs under RAW_DIR (2): ['mars', 'xuetangx']\n",
      "[01] 2025-12-28 23:11:47 | Expecting XuetangX raw folder: D:\\00_DS-ML-Workspace\\mooc-coldstart-session-meta\\data\\raw\\xuetangx\n",
      "[01] 2025-12-28 23:11:47 | Exists: True\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-04] Inventory data/raw and confirm XuetangX raw folder exists\n",
    "\n",
    "if RAW_DIR is None:\n",
    "    raise RuntimeError(\"RAW_DIR is None. Config loader did not resolve raw dir.\")\n",
    "\n",
    "if not RAW_DIR.exists():\n",
    "    raise FileNotFoundError(f\"RAW_DIR does not exist: {RAW_DIR}\")\n",
    "\n",
    "log(f\"Scanning RAW_DIR: {RAW_DIR}\")\n",
    "\n",
    "def human_bytes(n: int) -> str:\n",
    "    units = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]\n",
    "    f = float(n)\n",
    "    for u in units:\n",
    "        if f < 1024 or u == units[-1]:\n",
    "            return f\"{f:.2f} {u}\"\n",
    "        f /= 1024\n",
    "\n",
    "files = []\n",
    "for p in RAW_DIR.rglob(\"*\"):\n",
    "    if p.is_file():\n",
    "        try:\n",
    "            size = p.stat().st_size\n",
    "        except OSError:\n",
    "            size = None\n",
    "        files.append((p, size))\n",
    "\n",
    "log(f\"Found files: {len(files)}\")\n",
    "total = sum(s for _, s in files if isinstance(s, int))\n",
    "log(f\"Total size: {human_bytes(total)}\")\n",
    "\n",
    "subdirs = sorted([d for d in RAW_DIR.iterdir() if d.is_dir()])\n",
    "log(f\"Top-level subdirs under RAW_DIR ({len(subdirs)}): {[d.name for d in subdirs]}\")\n",
    "\n",
    "# Confirm xuetangx folder specifically\n",
    "XUETANGX_DIR = RAW_DIR / \"xuetangx\"\n",
    "log(f\"Expecting XuetangX raw folder: {XUETANGX_DIR}\")\n",
    "log(f\"Exists: {XUETANGX_DIR.exists()}\")\n",
    "\n",
    "if not XUETANGX_DIR.exists():\n",
    "    raise FileNotFoundError(\"Expected data/raw/xuetangx folder not found. Please place raw JSON files there.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa53b0",
   "metadata": {},
   "source": [
    "Explicitly select the “source MOOC dataset”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e38ad5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] 2025-12-28 23:12:14 | SOURCE_DIR: D:\\00_DS-ML-Workspace\\mooc-coldstart-session-meta\\data\\raw\\xuetangx\n",
      "[01] 2025-12-28 23:12:14 | SOURCE_DIR exists: True\n",
      "[01] 2025-12-28 23:12:14 | Raw XuetangX JSON files found: 6\n",
      "  - 20150801-20151101-raw_user_activity.json | 3.65 GB\n",
      "  - 20151101-20160201-raw_user_activity.json | 4.97 GB\n",
      "  - 20160201-20160501-raw_user_activity.json | 5.33 GB\n",
      "  - 20160501-20160801-raw_user_activity.json | 5.17 GB\n",
      "  - 20160801-20170201-raw_user_activity.json | 5.53 GB\n",
      "  - 20170201-20170801-raw_user_activity.json | 4.79 GB\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-05] Select which raw subdir is the source dataset\n",
    "\n",
    "SOURCE_DATASET_SUBDIR = \"xuetangx\"  # explicitly set\n",
    "\n",
    "SOURCE_DIR = (RAW_DIR / SOURCE_DATASET_SUBDIR).resolve()\n",
    "log(f\"SOURCE_DIR: {SOURCE_DIR}\")\n",
    "log(f\"SOURCE_DIR exists: {SOURCE_DIR.exists()}\")\n",
    "\n",
    "if not SOURCE_DIR.exists():\n",
    "    raise FileNotFoundError(f\"SOURCE_DIR does not exist: {SOURCE_DIR}\")\n",
    "\n",
    "json_files = sorted(SOURCE_DIR.glob(\"*raw_user_activity*.json\"))\n",
    "log(f\"Raw XuetangX JSON files found: {len(json_files)}\")\n",
    "for p in json_files:\n",
    "    print(f\"  - {p.name} | {human_bytes(p.stat().st_size)}\")\n",
    "\n",
    "if not json_files:\n",
    "    raise FileNotFoundError(\"No *raw_user_activity*.json files found in data/raw/xuetangx/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cace18",
   "metadata": {},
   "source": [
    "Quick HEAD/TAIL check (confirm JSON array + structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b1d07be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] 2025-12-28 23:12:55 | Inspecting: 20150801-20151101-raw_user_activity.json\n",
      "HEAD: b'[\\n  [\\n    \"course-v1:BIT+PHY1701601+2015_T2\", \\n    {\\n      \"1482755\": {\\n        \"2939ce48edf106610df7abbdf70b6862\": [\\n          [\\n            \"click_about\", \\n            \"2015-10-26T11:49:16\"\\n          ], \\n          [\\n  '\n",
      "TAIL: b'        ], \\n          [\\n            \"pause_video\", \\n            \"2015-10-20T21:53:24\"\\n          ], \\n          [\\n            \"close_courseware\", \\n            \"2015-10-20T21:53:30\"\\n          ]\\n        ]\\n      }\\n    }\\n  ]\\n]'\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-06] Confirm JSON structure via HEAD/TAIL bytes\n",
    "\n",
    "def head_tail_bytes(path: Path, n=220):\n",
    "    size = path.stat().st_size\n",
    "    with open(path, \"rb\") as f:\n",
    "        head = f.read(n)\n",
    "        f.seek(max(0, size - n))\n",
    "        tail = f.read(n)\n",
    "    return head, tail\n",
    "\n",
    "p = json_files[0]\n",
    "log(f\"Inspecting: {p.name}\")\n",
    "head, tail = head_tail_bytes(p)\n",
    "\n",
    "print(\"HEAD:\", head[:220])\n",
    "print(\"TAIL:\", tail[:220])\n",
    "\n",
    "# sanity: should start with '[' and end with ']'\n",
    "if not head.lstrip().startswith(b\"[\"):\n",
    "    log(\"⚠️ File does not appear to start with '['; structure might differ.\")\n",
    "if b\"]\" not in tail:\n",
    "    log(\"⚠️ File does not appear to end with ']'; structure might differ.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb55c0b",
   "metadata": {},
   "source": [
    "Install/Import dependencies (ijson, pyarrow, duckdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8ce1958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] 2025-12-28 23:13:32 | Installing duckdb ...\n",
      "[01] 2025-12-28 23:16:25 | All dependencies ready: ijson, pyarrow, duckdb\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-07] Ensure required libs are available: ijson, pyarrow, duckdb\n",
    "\n",
    "import importlib\n",
    "import subprocess\n",
    "\n",
    "def ensure(pkg: str, import_name: str = None):\n",
    "    name = import_name or pkg\n",
    "    try:\n",
    "        return importlib.import_module(name)\n",
    "    except Exception:\n",
    "        log(f\"Installing {pkg} ...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "        return importlib.import_module(name)\n",
    "\n",
    "ijson = ensure(\"ijson\")\n",
    "duckdb = ensure(\"duckdb\")\n",
    "pa = ensure(\"pyarrow\", \"pyarrow\")\n",
    "pq = ensure(\"pyarrow\", \"pyarrow.parquet\")\n",
    "\n",
    "log(\"All dependencies ready: ijson, pyarrow, duckdb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427b80aa",
   "metadata": {},
   "source": [
    "Stream-sample and summarize (no full load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398cdf13",
   "metadata": {},
   "source": [
    "This confirms: actions, time range, and typical nesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55d2954d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled file: 20150801-20151101-raw_user_activity.json\n",
      "Sampled courses: 5\n",
      "Sampled users: 250\n",
      "Sampled objects: 434\n",
      "Sampled events: 27745\n",
      "Sample time range: 2015-08-01 00:56:17 -> 2015-10-31 23:29:23\n",
      "\n",
      "Top actions:\n",
      "  play_video                3980\n",
      "  pause_video               3355\n",
      "  load_video                3279\n",
      "  stop_video                3209\n",
      "  problem_get               3192\n",
      "  problem_check             2060\n",
      "  seek_video                1955\n",
      "  close_courseware          1899\n",
      "  problem_check_correct     1428\n",
      "  click_courseware          1412\n",
      "  problem_check_incorrect   626\n",
      "  click_info                445\n",
      "  click_about               315\n",
      "  click_progress            281\n",
      "  problem_save              221\n",
      "  click_forum               76\n",
      "  create_comment            6\n",
      "  create_thread             3\n",
      "  reset_problem             3\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-08] Stream-sample raw JSON (K course blocks) and summarize actions/time range\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def iter_course_blocks(path: Path):\n",
    "    # top-level JSON is an array; each item is expected: [course_id, user_map]\n",
    "    with open(path, \"rb\") as f:\n",
    "        for item in ijson.items(f, \"item\"):\n",
    "            yield item\n",
    "\n",
    "def sample_summary(path: Path, K=5, max_users_per_course=50, max_events_per_object=500):\n",
    "    action_counts = Counter()\n",
    "    total_events = 0\n",
    "    total_users = 0\n",
    "    total_objects = 0\n",
    "    min_ts = None\n",
    "    max_ts = None\n",
    "\n",
    "    seen_courses = 0\n",
    "    for blk in iter_course_blocks(path):\n",
    "        if not (isinstance(blk, list) and len(blk) == 2):\n",
    "            continue\n",
    "\n",
    "        course_id, user_map = blk[0], blk[1]\n",
    "        if not (isinstance(course_id, str) and isinstance(user_map, dict)):\n",
    "            continue\n",
    "\n",
    "        seen_courses += 1\n",
    "\n",
    "        for ui, (user_id, obj_map) in enumerate(user_map.items()):\n",
    "            if ui >= max_users_per_course:\n",
    "                break\n",
    "            total_users += 1\n",
    "\n",
    "            if not isinstance(obj_map, dict):\n",
    "                continue\n",
    "\n",
    "            for obj_id, evs in obj_map.items():\n",
    "                total_objects += 1\n",
    "                if not isinstance(evs, list):\n",
    "                    continue\n",
    "\n",
    "                for ev in evs[:max_events_per_object]:\n",
    "                    if not (isinstance(ev, list) and len(ev) == 2):\n",
    "                        continue\n",
    "                    action, ts = ev[0], ev[1]\n",
    "                    action_counts[str(action)] += 1\n",
    "                    total_events += 1\n",
    "\n",
    "                    dt = pd.to_datetime(ts, errors=\"coerce\")\n",
    "                    if pd.notna(dt):\n",
    "                        if min_ts is None or dt < min_ts:\n",
    "                            min_ts = dt\n",
    "                        if max_ts is None or dt > max_ts:\n",
    "                            max_ts = dt\n",
    "\n",
    "        if seen_courses >= K:\n",
    "            break\n",
    "\n",
    "    print(f\"\\nSampled file: {path.name}\")\n",
    "    print(\"Sampled courses:\", seen_courses)\n",
    "    print(\"Sampled users:\", total_users)\n",
    "    print(\"Sampled objects:\", total_objects)\n",
    "    print(\"Sampled events:\", total_events)\n",
    "    print(\"Sample time range:\", min_ts, \"->\", max_ts)\n",
    "    print(\"\\nTop actions:\")\n",
    "    for a, c in action_counts.most_common(20):\n",
    "        print(f\"  {a:25s} {c}\")\n",
    "\n",
    "# sample the first file\n",
    "sample_summary(json_files[0], K=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28ac323",
   "metadata": {},
   "source": [
    "One-time conversion: Stream parse → Parquet shards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd39c02b",
   "metadata": {},
   "source": [
    "This creates a clean event table:\n",
    "course_id, user_id, object_id, action, ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbf05d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] 2025-12-28 23:30:38 | OUT_DIR: D:\\00_DS-ML-Workspace\\mooc-coldstart-session-meta\\data\\processed\\xuetangx_events_parquet\n",
      "[01] 2025-12-28 23:30:55 | 20150801-20151101-raw_user_activity.json | shards=1 | written=1,000,000 | elapsed=0.3m\n",
      "[01] 2025-12-28 23:30:57 | 20150801-20151101-raw_user_activity.json | shards=2 | written=2,000,000 | elapsed=0.3m\n",
      "[01] 2025-12-28 23:31:02 | 20150801-20151101-raw_user_activity.json | shards=3 | written=3,000,000 | elapsed=0.4m\n",
      "[01] 2025-12-28 23:31:09 | 20150801-20151101-raw_user_activity.json | shards=4 | written=4,000,000 | elapsed=0.5m\n",
      "[01] 2025-12-28 23:31:11 | 20150801-20151101-raw_user_activity.json | shards=5 | written=5,000,000 | elapsed=0.5m\n",
      "[01] 2025-12-28 23:31:14 | 20150801-20151101-raw_user_activity.json | shards=6 | written=6,000,000 | elapsed=0.6m\n",
      "[01] 2025-12-28 23:31:19 | 20150801-20151101-raw_user_activity.json | shards=7 | written=7,000,000 | elapsed=0.7m\n",
      "[01] 2025-12-28 23:31:23 | 20150801-20151101-raw_user_activity.json | shards=8 | written=8,000,000 | elapsed=0.7m\n",
      "[01] 2025-12-28 23:31:28 | 20150801-20151101-raw_user_activity.json | shards=9 | written=9,000,000 | elapsed=0.8m\n",
      "[01] 2025-12-28 23:31:31 | 20150801-20151101-raw_user_activity.json | shards=10 | written=10,000,000 | elapsed=0.9m\n",
      "[01] 2025-12-28 23:31:34 | 20150801-20151101-raw_user_activity.json | shards=11 | written=11,000,000 | elapsed=0.9m\n",
      "[01] 2025-12-28 23:31:39 | 20150801-20151101-raw_user_activity.json | shards=12 | written=12,000,000 | elapsed=1.0m\n",
      "[01] 2025-12-28 23:31:50 | 20150801-20151101-raw_user_activity.json | shards=13 | written=13,000,000 | elapsed=1.2m\n",
      "[01] 2025-12-28 23:31:55 | 20150801-20151101-raw_user_activity.json | shards=14 | written=14,000,000 | elapsed=1.3m\n",
      "[01] 2025-12-28 23:31:57 | 20150801-20151101-raw_user_activity.json | shards=15 | written=15,000,000 | elapsed=1.3m\n",
      "[01] 2025-12-28 23:31:59 | 20150801-20151101-raw_user_activity.json | shards=16 | written=16,000,000 | elapsed=1.3m\n",
      "[01] 2025-12-28 23:32:01 | 20150801-20151101-raw_user_activity.json | shards=17 | written=17,000,000 | elapsed=1.4m\n",
      "[01] 2025-12-28 23:32:03 | 20150801-20151101-raw_user_activity.json | shards=18 | written=18,000,000 | elapsed=1.4m\n",
      "[01] 2025-12-28 23:32:05 | 20150801-20151101-raw_user_activity.json | shards=19 | written=19,000,000 | elapsed=1.4m\n",
      "[01] 2025-12-28 23:32:07 | 20150801-20151101-raw_user_activity.json | shards=20 | written=20,000,000 | elapsed=1.5m\n",
      "[01] 2025-12-28 23:32:12 | 20150801-20151101-raw_user_activity.json | shards=21 | written=21,000,000 | elapsed=1.6m\n",
      "[01] 2025-12-28 23:32:15 | 20150801-20151101-raw_user_activity.json | shards=22 | written=22,000,000 | elapsed=1.6m\n",
      "[01] 2025-12-28 23:32:20 | 20150801-20151101-raw_user_activity.json | shards=23 | written=23,000,000 | elapsed=1.7m\n",
      "[01] 2025-12-28 23:32:23 | 20150801-20151101-raw_user_activity.json | shards=24 | written=24,000,000 | elapsed=1.7m\n",
      "[01] 2025-12-28 23:32:26 | 20150801-20151101-raw_user_activity.json | shards=25 | written=25,000,000 | elapsed=1.8m\n",
      "[01] 2025-12-28 23:32:31 | 20150801-20151101-raw_user_activity.json | shards=26 | written=26,000,000 | elapsed=1.9m\n",
      "[01] 2025-12-28 23:32:34 | 20150801-20151101-raw_user_activity.json | shards=27 | written=27,000,000 | elapsed=1.9m\n",
      "[01] 2025-12-28 23:32:39 | 20150801-20151101-raw_user_activity.json | shards=28 | written=28,000,000 | elapsed=2.0m\n",
      "[01] 2025-12-28 23:32:42 | 20150801-20151101-raw_user_activity.json | shards=29 | written=29,000,000 | elapsed=2.1m\n",
      "[01] 2025-12-28 23:32:44 | 20150801-20151101-raw_user_activity.json | shards=30 | written=30,000,000 | elapsed=2.1m\n",
      "[01] 2025-12-28 23:32:51 | 20150801-20151101-raw_user_activity.json | shards=31 | written=31,000,000 | elapsed=2.2m\n",
      "[01] 2025-12-28 23:32:53 | 20150801-20151101-raw_user_activity.json | shards=32 | written=32,000,000 | elapsed=2.2m\n",
      "[01] 2025-12-28 23:32:57 | 20150801-20151101-raw_user_activity.json | shards=33 | written=33,000,000 | elapsed=2.3m\n",
      "[01] 2025-12-28 23:33:01 | 20150801-20151101-raw_user_activity.json | shards=34 | written=34,000,000 | elapsed=2.4m\n",
      "[01] 2025-12-28 23:33:04 | 20150801-20151101-raw_user_activity.json | shards=35 | written=35,000,000 | elapsed=2.4m\n",
      "[01] 2025-12-28 23:33:09 | 20150801-20151101-raw_user_activity.json | shards=36 | written=36,000,000 | elapsed=2.5m\n",
      "[01] 2025-12-28 23:33:12 | 20150801-20151101-raw_user_activity.json | shards=37 | written=37,000,000 | elapsed=2.6m\n",
      "[01] 2025-12-28 23:33:15 | 20150801-20151101-raw_user_activity.json | shards=38 | written=38,000,000 | elapsed=2.6m\n",
      "[01] 2025-12-28 23:33:20 | 20150801-20151101-raw_user_activity.json | shards=39 | written=39,000,000 | elapsed=2.7m\n",
      "[01] 2025-12-28 23:33:23 | 20150801-20151101-raw_user_activity.json | shards=40 | written=40,000,000 | elapsed=2.7m\n",
      "[01] 2025-12-28 23:33:28 | 20150801-20151101-raw_user_activity.json | shards=41 | written=41,000,000 | elapsed=2.8m\n",
      "[01] 2025-12-28 23:33:31 | 20150801-20151101-raw_user_activity.json | shards=42 | written=42,000,000 | elapsed=2.9m\n",
      "[01] 2025-12-28 23:33:37 | 20150801-20151101-raw_user_activity.json | shards=43 | written=43,000,000 | elapsed=3.0m\n",
      "[01] 2025-12-28 23:33:39 | DONE 20150801-20151101-raw_user_activity.json | shards=44 | total_written=43,818,789 | elapsed=3.0m\n",
      "[01] 2025-12-28 23:33:42 | 20151101-20160201-raw_user_activity.json | shards=1 | written=1,000,000 | elapsed=0.1m\n",
      "[01] 2025-12-28 23:33:46 | 20151101-20160201-raw_user_activity.json | shards=2 | written=2,000,000 | elapsed=0.1m\n",
      "[01] 2025-12-28 23:33:50 | 20151101-20160201-raw_user_activity.json | shards=3 | written=3,000,000 | elapsed=0.2m\n",
      "[01] 2025-12-28 23:33:54 | 20151101-20160201-raw_user_activity.json | shards=4 | written=4,000,000 | elapsed=0.2m\n",
      "[01] 2025-12-28 23:33:59 | 20151101-20160201-raw_user_activity.json | shards=5 | written=5,000,000 | elapsed=0.3m\n",
      "[01] 2025-12-28 23:34:02 | 20151101-20160201-raw_user_activity.json | shards=6 | written=6,000,000 | elapsed=0.4m\n",
      "[01] 2025-12-28 23:34:08 | 20151101-20160201-raw_user_activity.json | shards=7 | written=7,000,000 | elapsed=0.5m\n",
      "[01] 2025-12-28 23:34:12 | 20151101-20160201-raw_user_activity.json | shards=8 | written=8,000,000 | elapsed=0.5m\n",
      "[01] 2025-12-28 23:34:15 | 20151101-20160201-raw_user_activity.json | shards=9 | written=9,000,000 | elapsed=0.6m\n",
      "[01] 2025-12-28 23:34:25 | 20151101-20160201-raw_user_activity.json | shards=10 | written=10,000,000 | elapsed=0.8m\n",
      "[01] 2025-12-28 23:34:28 | 20151101-20160201-raw_user_activity.json | shards=11 | written=11,000,000 | elapsed=0.8m\n",
      "[01] 2025-12-28 23:34:30 | 20151101-20160201-raw_user_activity.json | shards=12 | written=12,000,000 | elapsed=0.8m\n",
      "[01] 2025-12-28 23:34:32 | 20151101-20160201-raw_user_activity.json | shards=13 | written=13,000,000 | elapsed=0.9m\n",
      "[01] 2025-12-28 23:34:33 | 20151101-20160201-raw_user_activity.json | shards=14 | written=14,000,000 | elapsed=0.9m\n",
      "[01] 2025-12-28 23:34:36 | 20151101-20160201-raw_user_activity.json | shards=15 | written=15,000,000 | elapsed=0.9m\n",
      "[01] 2025-12-28 23:34:47 | 20151101-20160201-raw_user_activity.json | shards=16 | written=16,000,000 | elapsed=1.1m\n",
      "[01] 2025-12-28 23:34:49 | 20151101-20160201-raw_user_activity.json | shards=17 | written=17,000,000 | elapsed=1.2m\n",
      "[01] 2025-12-28 23:34:51 | 20151101-20160201-raw_user_activity.json | shards=18 | written=18,000,000 | elapsed=1.2m\n",
      "[01] 2025-12-28 23:34:53 | 20151101-20160201-raw_user_activity.json | shards=19 | written=19,000,000 | elapsed=1.2m\n",
      "[01] 2025-12-28 23:34:55 | 20151101-20160201-raw_user_activity.json | shards=20 | written=20,000,000 | elapsed=1.3m\n",
      "[01] 2025-12-28 23:34:58 | 20151101-20160201-raw_user_activity.json | shards=21 | written=21,000,000 | elapsed=1.3m\n",
      "[01] 2025-12-28 23:35:04 | 20151101-20160201-raw_user_activity.json | shards=22 | written=22,000,000 | elapsed=1.4m\n",
      "[01] 2025-12-28 23:35:06 | 20151101-20160201-raw_user_activity.json | shards=23 | written=23,000,000 | elapsed=1.5m\n",
      "[01] 2025-12-28 23:35:12 | 20151101-20160201-raw_user_activity.json | shards=24 | written=24,000,000 | elapsed=1.5m\n",
      "[01] 2025-12-28 23:35:14 | 20151101-20160201-raw_user_activity.json | shards=25 | written=25,000,000 | elapsed=1.6m\n",
      "[01] 2025-12-28 23:35:17 | 20151101-20160201-raw_user_activity.json | shards=26 | written=26,000,000 | elapsed=1.6m\n",
      "[01] 2025-12-28 23:35:22 | 20151101-20160201-raw_user_activity.json | shards=27 | written=27,000,000 | elapsed=1.7m\n",
      "[01] 2025-12-28 23:35:24 | 20151101-20160201-raw_user_activity.json | shards=28 | written=28,000,000 | elapsed=1.8m\n",
      "[01] 2025-12-28 23:35:30 | 20151101-20160201-raw_user_activity.json | shards=29 | written=29,000,000 | elapsed=1.8m\n",
      "[01] 2025-12-28 23:35:32 | 20151101-20160201-raw_user_activity.json | shards=30 | written=30,000,000 | elapsed=1.9m\n",
      "[01] 2025-12-28 23:35:36 | 20151101-20160201-raw_user_activity.json | shards=31 | written=31,000,000 | elapsed=1.9m\n",
      "[01] 2025-12-28 23:35:40 | 20151101-20160201-raw_user_activity.json | shards=32 | written=32,000,000 | elapsed=2.0m\n",
      "[01] 2025-12-28 23:35:44 | 20151101-20160201-raw_user_activity.json | shards=33 | written=33,000,000 | elapsed=2.1m\n",
      "[01] 2025-12-28 23:35:47 | 20151101-20160201-raw_user_activity.json | shards=34 | written=34,000,000 | elapsed=2.1m\n",
      "[01] 2025-12-28 23:35:52 | 20151101-20160201-raw_user_activity.json | shards=35 | written=35,000,000 | elapsed=2.2m\n",
      "[01] 2025-12-28 23:35:55 | 20151101-20160201-raw_user_activity.json | shards=36 | written=36,000,000 | elapsed=2.3m\n",
      "[01] 2025-12-28 23:36:01 | 20151101-20160201-raw_user_activity.json | shards=37 | written=37,000,000 | elapsed=2.4m\n",
      "[01] 2025-12-28 23:36:04 | 20151101-20160201-raw_user_activity.json | shards=38 | written=38,000,000 | elapsed=2.4m\n",
      "[01] 2025-12-28 23:36:07 | 20151101-20160201-raw_user_activity.json | shards=39 | written=39,000,000 | elapsed=2.5m\n",
      "[01] 2025-12-28 23:36:12 | 20151101-20160201-raw_user_activity.json | shards=40 | written=40,000,000 | elapsed=2.5m\n",
      "[01] 2025-12-28 23:36:15 | 20151101-20160201-raw_user_activity.json | shards=41 | written=41,000,000 | elapsed=2.6m\n",
      "[01] 2025-12-28 23:36:20 | 20151101-20160201-raw_user_activity.json | shards=42 | written=42,000,000 | elapsed=2.7m\n",
      "[01] 2025-12-28 23:36:23 | 20151101-20160201-raw_user_activity.json | shards=43 | written=43,000,000 | elapsed=2.7m\n",
      "[01] 2025-12-28 23:36:26 | 20151101-20160201-raw_user_activity.json | shards=44 | written=44,000,000 | elapsed=2.8m\n",
      "[01] 2025-12-28 23:36:31 | 20151101-20160201-raw_user_activity.json | shards=45 | written=45,000,000 | elapsed=2.9m\n",
      "[01] 2025-12-28 23:36:35 | 20151101-20160201-raw_user_activity.json | shards=46 | written=46,000,000 | elapsed=2.9m\n",
      "[01] 2025-12-28 23:36:41 | 20151101-20160201-raw_user_activity.json | shards=47 | written=47,000,000 | elapsed=3.0m\n",
      "[01] 2025-12-28 23:36:44 | 20151101-20160201-raw_user_activity.json | shards=48 | written=48,000,000 | elapsed=3.1m\n",
      "[01] 2025-12-28 23:36:49 | 20151101-20160201-raw_user_activity.json | shards=49 | written=49,000,000 | elapsed=3.2m\n",
      "[01] 2025-12-28 23:36:54 | 20151101-20160201-raw_user_activity.json | shards=50 | written=50,000,000 | elapsed=3.2m\n",
      "[01] 2025-12-28 23:36:58 | 20151101-20160201-raw_user_activity.json | shards=51 | written=51,000,000 | elapsed=3.3m\n",
      "[01] 2025-12-28 23:37:00 | 20151101-20160201-raw_user_activity.json | shards=52 | written=52,000,000 | elapsed=3.4m\n",
      "[01] 2025-12-28 23:37:04 | 20151101-20160201-raw_user_activity.json | shards=53 | written=53,000,000 | elapsed=3.4m\n",
      "[01] 2025-12-28 23:37:12 | 20151101-20160201-raw_user_activity.json | shards=54 | written=54,000,000 | elapsed=3.5m\n",
      "[01] 2025-12-28 23:37:14 | 20151101-20160201-raw_user_activity.json | shards=55 | written=55,000,000 | elapsed=3.6m\n",
      "[01] 2025-12-28 23:37:16 | 20151101-20160201-raw_user_activity.json | shards=56 | written=56,000,000 | elapsed=3.6m\n",
      "[01] 2025-12-28 23:37:21 | 20151101-20160201-raw_user_activity.json | shards=57 | written=57,000,000 | elapsed=3.7m\n",
      "[01] 2025-12-28 23:37:23 | 20151101-20160201-raw_user_activity.json | shards=58 | written=58,000,000 | elapsed=3.7m\n",
      "[01] 2025-12-28 23:37:27 | 20151101-20160201-raw_user_activity.json | shards=59 | written=59,000,000 | elapsed=3.8m\n",
      "[01] 2025-12-28 23:37:28 | DONE 20151101-20160201-raw_user_activity.json | shards=60 | total_written=59,430,567 | elapsed=3.8m\n",
      "[01] 2025-12-28 23:37:33 | 20160201-20160501-raw_user_activity.json | shards=1 | written=1,000,000 | elapsed=0.1m\n",
      "[01] 2025-12-28 23:37:37 | 20160201-20160501-raw_user_activity.json | shards=2 | written=2,000,000 | elapsed=0.1m\n",
      "[01] 2025-12-28 23:37:40 | 20160201-20160501-raw_user_activity.json | shards=3 | written=3,000,000 | elapsed=0.2m\n",
      "[01] 2025-12-28 23:37:45 | 20160201-20160501-raw_user_activity.json | shards=4 | written=4,000,000 | elapsed=0.3m\n",
      "[01] 2025-12-28 23:37:48 | 20160201-20160501-raw_user_activity.json | shards=5 | written=5,000,000 | elapsed=0.3m\n",
      "[01] 2025-12-28 23:37:54 | 20160201-20160501-raw_user_activity.json | shards=6 | written=6,000,000 | elapsed=0.4m\n",
      "[01] 2025-12-28 23:37:57 | 20160201-20160501-raw_user_activity.json | shards=7 | written=7,000,000 | elapsed=0.5m\n",
      "[01] 2025-12-28 23:38:00 | 20160201-20160501-raw_user_activity.json | shards=8 | written=8,000,000 | elapsed=0.5m\n",
      "[01] 2025-12-28 23:38:05 | 20160201-20160501-raw_user_activity.json | shards=9 | written=9,000,000 | elapsed=0.6m\n",
      "[01] 2025-12-28 23:38:07 | 20160201-20160501-raw_user_activity.json | shards=10 | written=10,000,000 | elapsed=0.7m\n",
      "[01] 2025-12-28 23:38:13 | 20160201-20160501-raw_user_activity.json | shards=11 | written=11,000,000 | elapsed=0.7m\n",
      "[01] 2025-12-28 23:38:16 | 20160201-20160501-raw_user_activity.json | shards=12 | written=12,000,000 | elapsed=0.8m\n",
      "[01] 2025-12-28 23:38:19 | 20160201-20160501-raw_user_activity.json | shards=13 | written=13,000,000 | elapsed=0.8m\n",
      "[01] 2025-12-28 23:38:24 | 20160201-20160501-raw_user_activity.json | shards=14 | written=14,000,000 | elapsed=0.9m\n",
      "[01] 2025-12-28 23:38:29 | 20160201-20160501-raw_user_activity.json | shards=15 | written=15,000,000 | elapsed=1.0m\n",
      "[01] 2025-12-28 23:38:32 | 20160201-20160501-raw_user_activity.json | shards=16 | written=16,000,000 | elapsed=1.1m\n",
      "[01] 2025-12-28 23:38:37 | 20160201-20160501-raw_user_activity.json | shards=17 | written=17,000,000 | elapsed=1.1m\n",
      "[01] 2025-12-28 23:38:42 | 20160201-20160501-raw_user_activity.json | shards=18 | written=18,000,000 | elapsed=1.2m\n",
      "[01] 2025-12-28 23:38:46 | 20160201-20160501-raw_user_activity.json | shards=19 | written=19,000,000 | elapsed=1.3m\n",
      "[01] 2025-12-28 23:38:49 | 20160201-20160501-raw_user_activity.json | shards=20 | written=20,000,000 | elapsed=1.3m\n",
      "[01] 2025-12-28 23:38:52 | 20160201-20160501-raw_user_activity.json | shards=21 | written=21,000,000 | elapsed=1.4m\n",
      "[01] 2025-12-28 23:38:57 | 20160201-20160501-raw_user_activity.json | shards=22 | written=22,000,000 | elapsed=1.5m\n",
      "[01] 2025-12-28 23:39:00 | 20160201-20160501-raw_user_activity.json | shards=23 | written=23,000,000 | elapsed=1.5m\n",
      "[01] 2025-12-28 23:39:05 | 20160201-20160501-raw_user_activity.json | shards=24 | written=24,000,000 | elapsed=1.6m\n",
      "[01] 2025-12-28 23:39:08 | 20160201-20160501-raw_user_activity.json | shards=25 | written=25,000,000 | elapsed=1.7m\n",
      "[01] 2025-12-28 23:39:11 | 20160201-20160501-raw_user_activity.json | shards=26 | written=26,000,000 | elapsed=1.7m\n",
      "[01] 2025-12-28 23:39:17 | 20160201-20160501-raw_user_activity.json | shards=27 | written=27,000,000 | elapsed=1.8m\n",
      "[01] 2025-12-28 23:39:19 | 20160201-20160501-raw_user_activity.json | shards=28 | written=28,000,000 | elapsed=1.9m\n",
      "[01] 2025-12-28 23:39:26 | 20160201-20160501-raw_user_activity.json | shards=29 | written=29,000,000 | elapsed=2.0m\n",
      "[01] 2025-12-28 23:39:28 | 20160201-20160501-raw_user_activity.json | shards=30 | written=30,000,000 | elapsed=2.0m\n",
      "[01] 2025-12-28 23:39:30 | 20160201-20160501-raw_user_activity.json | shards=31 | written=31,000,000 | elapsed=2.0m\n",
      "[01] 2025-12-28 23:39:35 | 20160201-20160501-raw_user_activity.json | shards=32 | written=32,000,000 | elapsed=2.1m\n",
      "[01] 2025-12-28 23:39:38 | 20160201-20160501-raw_user_activity.json | shards=33 | written=33,000,000 | elapsed=2.2m\n",
      "[01] 2025-12-28 23:39:41 | 20160201-20160501-raw_user_activity.json | shards=34 | written=34,000,000 | elapsed=2.2m\n",
      "[01] 2025-12-28 23:39:46 | 20160201-20160501-raw_user_activity.json | shards=35 | written=35,000,000 | elapsed=2.3m\n",
      "[01] 2025-12-28 23:39:49 | 20160201-20160501-raw_user_activity.json | shards=36 | written=36,000,000 | elapsed=2.3m\n",
      "[01] 2025-12-28 23:39:53 | 20160201-20160501-raw_user_activity.json | shards=37 | written=37,000,000 | elapsed=2.4m\n",
      "[01] 2025-12-28 23:40:01 | 20160201-20160501-raw_user_activity.json | shards=38 | written=38,000,000 | elapsed=2.5m\n",
      "[01] 2025-12-28 23:40:03 | 20160201-20160501-raw_user_activity.json | shards=39 | written=39,000,000 | elapsed=2.6m\n",
      "[01] 2025-12-28 23:40:05 | 20160201-20160501-raw_user_activity.json | shards=40 | written=40,000,000 | elapsed=2.6m\n",
      "[01] 2025-12-28 23:40:07 | 20160201-20160501-raw_user_activity.json | shards=41 | written=41,000,000 | elapsed=2.7m\n",
      "[01] 2025-12-28 23:40:11 | 20160201-20160501-raw_user_activity.json | shards=42 | written=42,000,000 | elapsed=2.7m\n",
      "[01] 2025-12-28 23:40:16 | 20160201-20160501-raw_user_activity.json | shards=43 | written=43,000,000 | elapsed=2.8m\n",
      "[01] 2025-12-28 23:40:19 | 20160201-20160501-raw_user_activity.json | shards=44 | written=44,000,000 | elapsed=2.8m\n",
      "[01] 2025-12-28 23:40:24 | 20160201-20160501-raw_user_activity.json | shards=45 | written=45,000,000 | elapsed=2.9m\n",
      "[01] 2025-12-28 23:40:28 | 20160201-20160501-raw_user_activity.json | shards=46 | written=46,000,000 | elapsed=3.0m\n",
      "[01] 2025-12-28 23:40:31 | 20160201-20160501-raw_user_activity.json | shards=47 | written=47,000,000 | elapsed=3.0m\n",
      "[01] 2025-12-28 23:40:44 | 20160201-20160501-raw_user_activity.json | shards=48 | written=48,000,000 | elapsed=3.3m\n",
      "[01] 2025-12-28 23:40:46 | 20160201-20160501-raw_user_activity.json | shards=49 | written=49,000,000 | elapsed=3.3m\n",
      "[01] 2025-12-28 23:40:48 | 20160201-20160501-raw_user_activity.json | shards=50 | written=50,000,000 | elapsed=3.3m\n",
      "[01] 2025-12-28 23:40:50 | 20160201-20160501-raw_user_activity.json | shards=51 | written=51,000,000 | elapsed=3.4m\n",
      "[01] 2025-12-28 23:40:54 | 20160201-20160501-raw_user_activity.json | shards=52 | written=52,000,000 | elapsed=3.4m\n",
      "[01] 2025-12-28 23:40:56 | 20160201-20160501-raw_user_activity.json | shards=53 | written=53,000,000 | elapsed=3.5m\n",
      "[01] 2025-12-28 23:40:58 | 20160201-20160501-raw_user_activity.json | shards=54 | written=54,000,000 | elapsed=3.5m\n",
      "[01] 2025-12-28 23:41:01 | 20160201-20160501-raw_user_activity.json | shards=55 | written=55,000,000 | elapsed=3.6m\n",
      "[01] 2025-12-28 23:41:05 | 20160201-20160501-raw_user_activity.json | shards=56 | written=56,000,000 | elapsed=3.6m\n",
      "[01] 2025-12-28 23:41:11 | 20160201-20160501-raw_user_activity.json | shards=57 | written=57,000,000 | elapsed=3.7m\n",
      "[01] 2025-12-28 23:41:15 | 20160201-20160501-raw_user_activity.json | shards=58 | written=58,000,000 | elapsed=3.8m\n",
      "[01] 2025-12-28 23:41:20 | 20160201-20160501-raw_user_activity.json | shards=59 | written=59,000,000 | elapsed=3.9m\n",
      "[01] 2025-12-28 23:41:23 | 20160201-20160501-raw_user_activity.json | shards=60 | written=60,000,000 | elapsed=3.9m\n",
      "[01] 2025-12-28 23:41:26 | 20160201-20160501-raw_user_activity.json | shards=61 | written=61,000,000 | elapsed=4.0m\n",
      "[01] 2025-12-28 23:41:31 | 20160201-20160501-raw_user_activity.json | shards=62 | written=62,000,000 | elapsed=4.0m\n",
      "[01] 2025-12-28 23:41:34 | 20160201-20160501-raw_user_activity.json | shards=63 | written=63,000,000 | elapsed=4.1m\n",
      "[01] 2025-12-28 23:41:36 | DONE 20160201-20160501-raw_user_activity.json | shards=64 | total_written=63,745,152 | elapsed=4.1m\n",
      "[01] 2025-12-28 23:41:41 | 20160501-20160801-raw_user_activity.json | shards=1 | written=1,000,000 | elapsed=0.1m\n",
      "[01] 2025-12-28 23:41:45 | 20160501-20160801-raw_user_activity.json | shards=2 | written=2,000,000 | elapsed=0.2m\n",
      "[01] 2025-12-28 23:41:51 | 20160501-20160801-raw_user_activity.json | shards=3 | written=3,000,000 | elapsed=0.3m\n",
      "[01] 2025-12-28 23:41:53 | 20160501-20160801-raw_user_activity.json | shards=4 | written=4,000,000 | elapsed=0.3m\n",
      "[01] 2025-12-28 23:41:56 | 20160501-20160801-raw_user_activity.json | shards=5 | written=5,000,000 | elapsed=0.3m\n",
      "[01] 2025-12-28 23:41:59 | 20160501-20160801-raw_user_activity.json | shards=6 | written=6,000,000 | elapsed=0.4m\n",
      "[01] 2025-12-28 23:42:04 | 20160501-20160801-raw_user_activity.json | shards=7 | written=7,000,000 | elapsed=0.5m\n",
      "[01] 2025-12-28 23:42:07 | 20160501-20160801-raw_user_activity.json | shards=8 | written=8,000,000 | elapsed=0.5m\n",
      "[01] 2025-12-28 23:42:14 | 20160501-20160801-raw_user_activity.json | shards=9 | written=9,000,000 | elapsed=0.6m\n",
      "[01] 2025-12-28 23:42:16 | 20160501-20160801-raw_user_activity.json | shards=10 | written=10,000,000 | elapsed=0.7m\n",
      "[01] 2025-12-28 23:42:19 | 20160501-20160801-raw_user_activity.json | shards=11 | written=11,000,000 | elapsed=0.7m\n",
      "[01] 2025-12-28 23:42:24 | 20160501-20160801-raw_user_activity.json | shards=12 | written=12,000,000 | elapsed=0.8m\n",
      "[01] 2025-12-28 23:42:27 | 20160501-20160801-raw_user_activity.json | shards=13 | written=13,000,000 | elapsed=0.9m\n",
      "[01] 2025-12-28 23:42:32 | 20160501-20160801-raw_user_activity.json | shards=14 | written=14,000,000 | elapsed=0.9m\n",
      "[01] 2025-12-28 23:42:35 | 20160501-20160801-raw_user_activity.json | shards=15 | written=15,000,000 | elapsed=1.0m\n",
      "[01] 2025-12-28 23:42:38 | 20160501-20160801-raw_user_activity.json | shards=16 | written=16,000,000 | elapsed=1.0m\n",
      "[01] 2025-12-28 23:42:43 | 20160501-20160801-raw_user_activity.json | shards=17 | written=17,000,000 | elapsed=1.1m\n",
      "[01] 2025-12-28 23:42:46 | 20160501-20160801-raw_user_activity.json | shards=18 | written=18,000,000 | elapsed=1.2m\n",
      "[01] 2025-12-28 23:42:50 | 20160501-20160801-raw_user_activity.json | shards=19 | written=19,000,000 | elapsed=1.2m\n",
      "[01] 2025-12-28 23:42:53 | 20160501-20160801-raw_user_activity.json | shards=20 | written=20,000,000 | elapsed=1.3m\n",
      "[01] 2025-12-28 23:42:56 | 20160501-20160801-raw_user_activity.json | shards=21 | written=21,000,000 | elapsed=1.3m\n",
      "[01] 2025-12-28 23:43:01 | 20160501-20160801-raw_user_activity.json | shards=22 | written=22,000,000 | elapsed=1.4m\n",
      "[01] 2025-12-28 23:43:04 | 20160501-20160801-raw_user_activity.json | shards=23 | written=23,000,000 | elapsed=1.5m\n",
      "[01] 2025-12-28 23:43:09 | 20160501-20160801-raw_user_activity.json | shards=24 | written=24,000,000 | elapsed=1.6m\n",
      "[01] 2025-12-28 23:43:12 | 20160501-20160801-raw_user_activity.json | shards=25 | written=25,000,000 | elapsed=1.6m\n",
      "[01] 2025-12-28 23:43:15 | 20160501-20160801-raw_user_activity.json | shards=26 | written=26,000,000 | elapsed=1.6m\n",
      "[01] 2025-12-28 23:43:20 | 20160501-20160801-raw_user_activity.json | shards=27 | written=27,000,000 | elapsed=1.7m\n",
      "[01] 2025-12-28 23:43:22 | 20160501-20160801-raw_user_activity.json | shards=28 | written=28,000,000 | elapsed=1.8m\n",
      "[01] 2025-12-28 23:43:28 | 20160501-20160801-raw_user_activity.json | shards=29 | written=29,000,000 | elapsed=1.9m\n",
      "[01] 2025-12-28 23:43:30 | 20160501-20160801-raw_user_activity.json | shards=30 | written=30,000,000 | elapsed=1.9m\n",
      "[01] 2025-12-28 23:43:33 | 20160501-20160801-raw_user_activity.json | shards=31 | written=31,000,000 | elapsed=2.0m\n",
      "[01] 2025-12-28 23:43:39 | 20160501-20160801-raw_user_activity.json | shards=32 | written=32,000,000 | elapsed=2.1m\n",
      "[01] 2025-12-28 23:43:42 | 20160501-20160801-raw_user_activity.json | shards=33 | written=33,000,000 | elapsed=2.1m\n",
      "[01] 2025-12-28 23:43:48 | 20160501-20160801-raw_user_activity.json | shards=34 | written=34,000,000 | elapsed=2.2m\n",
      "[01] 2025-12-28 23:43:51 | 20160501-20160801-raw_user_activity.json | shards=35 | written=35,000,000 | elapsed=2.3m\n",
      "[01] 2025-12-28 23:43:54 | 20160501-20160801-raw_user_activity.json | shards=36 | written=36,000,000 | elapsed=2.3m\n",
      "[01] 2025-12-28 23:43:59 | 20160501-20160801-raw_user_activity.json | shards=37 | written=37,000,000 | elapsed=2.4m\n",
      "[01] 2025-12-28 23:44:03 | 20160501-20160801-raw_user_activity.json | shards=38 | written=38,000,000 | elapsed=2.5m\n",
      "[01] 2025-12-28 23:44:08 | 20160501-20160801-raw_user_activity.json | shards=39 | written=39,000,000 | elapsed=2.5m\n",
      "[01] 2025-12-28 23:44:12 | 20160501-20160801-raw_user_activity.json | shards=40 | written=40,000,000 | elapsed=2.6m\n",
      "[01] 2025-12-28 23:44:14 | 20160501-20160801-raw_user_activity.json | shards=41 | written=41,000,000 | elapsed=2.6m\n",
      "[01] 2025-12-28 23:44:20 | 20160501-20160801-raw_user_activity.json | shards=42 | written=42,000,000 | elapsed=2.7m\n",
      "[01] 2025-12-28 23:44:23 | 20160501-20160801-raw_user_activity.json | shards=43 | written=43,000,000 | elapsed=2.8m\n",
      "[01] 2025-12-28 23:44:26 | 20160501-20160801-raw_user_activity.json | shards=44 | written=44,000,000 | elapsed=2.8m\n",
      "[01] 2025-12-28 23:44:31 | 20160501-20160801-raw_user_activity.json | shards=45 | written=45,000,000 | elapsed=2.9m\n",
      "[01] 2025-12-28 23:44:33 | 20160501-20160801-raw_user_activity.json | shards=46 | written=46,000,000 | elapsed=3.0m\n",
      "[01] 2025-12-28 23:44:38 | 20160501-20160801-raw_user_activity.json | shards=47 | written=47,000,000 | elapsed=3.0m\n",
      "[01] 2025-12-28 23:44:41 | 20160501-20160801-raw_user_activity.json | shards=48 | written=48,000,000 | elapsed=3.1m\n",
      "[01] 2025-12-28 23:44:44 | 20160501-20160801-raw_user_activity.json | shards=49 | written=49,000,000 | elapsed=3.1m\n",
      "[01] 2025-12-28 23:44:51 | 20160501-20160801-raw_user_activity.json | shards=50 | written=50,000,000 | elapsed=3.3m\n",
      "[01] 2025-12-28 23:44:55 | 20160501-20160801-raw_user_activity.json | shards=51 | written=51,000,000 | elapsed=3.3m\n",
      "[01] 2025-12-28 23:44:57 | 20160501-20160801-raw_user_activity.json | shards=52 | written=52,000,000 | elapsed=3.4m\n",
      "[01] 2025-12-28 23:44:59 | 20160501-20160801-raw_user_activity.json | shards=53 | written=53,000,000 | elapsed=3.4m\n",
      "[01] 2025-12-28 23:45:03 | 20160501-20160801-raw_user_activity.json | shards=54 | written=54,000,000 | elapsed=3.5m\n",
      "[01] 2025-12-28 23:45:08 | 20160501-20160801-raw_user_activity.json | shards=55 | written=55,000,000 | elapsed=3.5m\n",
      "[01] 2025-12-28 23:45:10 | 20160501-20160801-raw_user_activity.json | shards=56 | written=56,000,000 | elapsed=3.6m\n",
      "[01] 2025-12-28 23:45:13 | 20160501-20160801-raw_user_activity.json | shards=57 | written=57,000,000 | elapsed=3.6m\n",
      "[01] 2025-12-28 23:45:18 | 20160501-20160801-raw_user_activity.json | shards=58 | written=58,000,000 | elapsed=3.7m\n",
      "[01] 2025-12-28 23:45:21 | 20160501-20160801-raw_user_activity.json | shards=59 | written=59,000,000 | elapsed=3.8m\n",
      "[01] 2025-12-28 23:45:26 | 20160501-20160801-raw_user_activity.json | shards=60 | written=60,000,000 | elapsed=3.8m\n",
      "[01] 2025-12-28 23:45:29 | 20160501-20160801-raw_user_activity.json | shards=61 | written=61,000,000 | elapsed=3.9m\n",
      "[01] 2025-12-28 23:45:31 | DONE 20160501-20160801-raw_user_activity.json | shards=62 | total_written=61,676,966 | elapsed=3.9m\n",
      "[01] 2025-12-28 23:45:36 | 20160801-20170201-raw_user_activity.json | shards=1 | written=1,000,000 | elapsed=0.1m\n",
      "[01] 2025-12-28 23:45:39 | 20160801-20170201-raw_user_activity.json | shards=2 | written=2,000,000 | elapsed=0.1m\n",
      "[01] 2025-12-28 23:45:44 | 20160801-20170201-raw_user_activity.json | shards=3 | written=3,000,000 | elapsed=0.2m\n",
      "[01] 2025-12-28 23:45:47 | 20160801-20170201-raw_user_activity.json | shards=4 | written=4,000,000 | elapsed=0.3m\n",
      "[01] 2025-12-28 23:45:50 | 20160801-20170201-raw_user_activity.json | shards=5 | written=5,000,000 | elapsed=0.3m\n",
      "[01] 2025-12-28 23:45:55 | 20160801-20170201-raw_user_activity.json | shards=6 | written=6,000,000 | elapsed=0.4m\n",
      "[01] 2025-12-28 23:45:58 | 20160801-20170201-raw_user_activity.json | shards=7 | written=7,000,000 | elapsed=0.5m\n",
      "[01] 2025-12-28 23:46:00 | 20160801-20170201-raw_user_activity.json | shards=8 | written=8,000,000 | elapsed=0.5m\n",
      "[01] 2025-12-28 23:46:05 | 20160801-20170201-raw_user_activity.json | shards=9 | written=9,000,000 | elapsed=0.6m\n",
      "[01] 2025-12-28 23:46:08 | 20160801-20170201-raw_user_activity.json | shards=10 | written=10,000,000 | elapsed=0.6m\n",
      "[01] 2025-12-28 23:46:14 | 20160801-20170201-raw_user_activity.json | shards=11 | written=11,000,000 | elapsed=0.7m\n",
      "[01] 2025-12-28 23:46:17 | 20160801-20170201-raw_user_activity.json | shards=12 | written=12,000,000 | elapsed=0.8m\n",
      "[01] 2025-12-28 23:46:25 | 20160801-20170201-raw_user_activity.json | shards=13 | written=13,000,000 | elapsed=0.9m\n",
      "[01] 2025-12-28 23:46:27 | 20160801-20170201-raw_user_activity.json | shards=14 | written=14,000,000 | elapsed=0.9m\n",
      "[01] 2025-12-28 23:46:29 | 20160801-20170201-raw_user_activity.json | shards=15 | written=15,000,000 | elapsed=1.0m\n",
      "[01] 2025-12-28 23:46:34 | 20160801-20170201-raw_user_activity.json | shards=16 | written=16,000,000 | elapsed=1.1m\n",
      "[01] 2025-12-28 23:46:38 | 20160801-20170201-raw_user_activity.json | shards=17 | written=17,000,000 | elapsed=1.1m\n",
      "[01] 2025-12-28 23:46:41 | 20160801-20170201-raw_user_activity.json | shards=18 | written=18,000,000 | elapsed=1.2m\n",
      "[01] 2025-12-28 23:46:44 | 20160801-20170201-raw_user_activity.json | shards=19 | written=19,000,000 | elapsed=1.2m\n",
      "[01] 2025-12-28 23:46:49 | 20160801-20170201-raw_user_activity.json | shards=20 | written=20,000,000 | elapsed=1.3m\n",
      "[01] 2025-12-28 23:46:51 | 20160801-20170201-raw_user_activity.json | shards=21 | written=21,000,000 | elapsed=1.3m\n",
      "[01] 2025-12-28 23:46:57 | 20160801-20170201-raw_user_activity.json | shards=22 | written=22,000,000 | elapsed=1.4m\n",
      "[01] 2025-12-28 23:47:00 | 20160801-20170201-raw_user_activity.json | shards=23 | written=23,000,000 | elapsed=1.5m\n",
      "[01] 2025-12-28 23:47:03 | 20160801-20170201-raw_user_activity.json | shards=24 | written=24,000,000 | elapsed=1.5m\n",
      "[01] 2025-12-28 23:47:08 | 20160801-20170201-raw_user_activity.json | shards=25 | written=25,000,000 | elapsed=1.6m\n",
      "[01] 2025-12-28 23:47:11 | 20160801-20170201-raw_user_activity.json | shards=26 | written=26,000,000 | elapsed=1.7m\n",
      "[01] 2025-12-28 23:47:17 | 20160801-20170201-raw_user_activity.json | shards=27 | written=27,000,000 | elapsed=1.8m\n",
      "[01] 2025-12-28 23:47:19 | 20160801-20170201-raw_user_activity.json | shards=28 | written=28,000,000 | elapsed=1.8m\n",
      "[01] 2025-12-28 23:47:22 | 20160801-20170201-raw_user_activity.json | shards=29 | written=29,000,000 | elapsed=1.8m\n",
      "[01] 2025-12-28 23:47:28 | 20160801-20170201-raw_user_activity.json | shards=30 | written=30,000,000 | elapsed=1.9m\n",
      "[01] 2025-12-28 23:47:31 | 20160801-20170201-raw_user_activity.json | shards=31 | written=31,000,000 | elapsed=2.0m\n",
      "[01] 2025-12-28 23:47:36 | 20160801-20170201-raw_user_activity.json | shards=32 | written=32,000,000 | elapsed=2.1m\n",
      "[01] 2025-12-28 23:47:39 | 20160801-20170201-raw_user_activity.json | shards=33 | written=33,000,000 | elapsed=2.1m\n",
      "[01] 2025-12-28 23:47:42 | 20160801-20170201-raw_user_activity.json | shards=34 | written=34,000,000 | elapsed=2.2m\n",
      "[01] 2025-12-28 23:47:47 | 20160801-20170201-raw_user_activity.json | shards=35 | written=35,000,000 | elapsed=2.3m\n",
      "[01] 2025-12-28 23:47:50 | 20160801-20170201-raw_user_activity.json | shards=36 | written=36,000,000 | elapsed=2.3m\n",
      "[01] 2025-12-28 23:47:53 | 20160801-20170201-raw_user_activity.json | shards=37 | written=37,000,000 | elapsed=2.4m\n",
      "[01] 2025-12-28 23:47:57 | 20160801-20170201-raw_user_activity.json | shards=38 | written=38,000,000 | elapsed=2.4m\n",
      "[01] 2025-12-28 23:48:01 | 20160801-20170201-raw_user_activity.json | shards=39 | written=39,000,000 | elapsed=2.5m\n",
      "[01] 2025-12-28 23:48:06 | 20160801-20170201-raw_user_activity.json | shards=40 | written=40,000,000 | elapsed=2.6m\n",
      "[01] 2025-12-28 23:48:09 | 20160801-20170201-raw_user_activity.json | shards=41 | written=41,000,000 | elapsed=2.6m\n",
      "[01] 2025-12-28 23:48:13 | 20160801-20170201-raw_user_activity.json | shards=42 | written=42,000,000 | elapsed=2.7m\n",
      "[01] 2025-12-28 23:48:18 | 20160801-20170201-raw_user_activity.json | shards=43 | written=43,000,000 | elapsed=2.8m\n",
      "[01] 2025-12-28 23:48:22 | 20160801-20170201-raw_user_activity.json | shards=44 | written=44,000,000 | elapsed=2.8m\n",
      "[01] 2025-12-28 23:48:27 | 20160801-20170201-raw_user_activity.json | shards=45 | written=45,000,000 | elapsed=2.9m\n",
      "[01] 2025-12-28 23:48:30 | 20160801-20170201-raw_user_activity.json | shards=46 | written=46,000,000 | elapsed=3.0m\n",
      "[01] 2025-12-28 23:48:33 | 20160801-20170201-raw_user_activity.json | shards=47 | written=47,000,000 | elapsed=3.0m\n",
      "[01] 2025-12-28 23:48:38 | 20160801-20170201-raw_user_activity.json | shards=48 | written=48,000,000 | elapsed=3.1m\n",
      "[01] 2025-12-28 23:48:41 | 20160801-20170201-raw_user_activity.json | shards=49 | written=49,000,000 | elapsed=3.2m\n",
      "[01] 2025-12-28 23:48:46 | 20160801-20170201-raw_user_activity.json | shards=50 | written=50,000,000 | elapsed=3.3m\n",
      "[01] 2025-12-28 23:48:50 | 20160801-20170201-raw_user_activity.json | shards=51 | written=51,000,000 | elapsed=3.3m\n",
      "[01] 2025-12-28 23:48:53 | 20160801-20170201-raw_user_activity.json | shards=52 | written=52,000,000 | elapsed=3.4m\n",
      "[01] 2025-12-28 23:48:58 | 20160801-20170201-raw_user_activity.json | shards=53 | written=53,000,000 | elapsed=3.4m\n",
      "[01] 2025-12-28 23:49:01 | 20160801-20170201-raw_user_activity.json | shards=54 | written=54,000,000 | elapsed=3.5m\n",
      "[01] 2025-12-28 23:49:06 | 20160801-20170201-raw_user_activity.json | shards=55 | written=55,000,000 | elapsed=3.6m\n",
      "[01] 2025-12-28 23:49:15 | 20160801-20170201-raw_user_activity.json | shards=56 | written=56,000,000 | elapsed=3.7m\n",
      "[01] 2025-12-28 23:49:17 | 20160801-20170201-raw_user_activity.json | shards=57 | written=57,000,000 | elapsed=3.8m\n",
      "[01] 2025-12-28 23:49:19 | 20160801-20170201-raw_user_activity.json | shards=58 | written=58,000,000 | elapsed=3.8m\n",
      "[01] 2025-12-28 23:49:21 | 20160801-20170201-raw_user_activity.json | shards=59 | written=59,000,000 | elapsed=3.8m\n",
      "[01] 2025-12-28 23:49:22 | 20160801-20170201-raw_user_activity.json | shards=60 | written=60,000,000 | elapsed=3.9m\n",
      "[01] 2025-12-28 23:49:28 | 20160801-20170201-raw_user_activity.json | shards=61 | written=61,000,000 | elapsed=4.0m\n",
      "[01] 2025-12-28 23:49:31 | 20160801-20170201-raw_user_activity.json | shards=62 | written=62,000,000 | elapsed=4.0m\n",
      "[01] 2025-12-28 23:49:36 | 20160801-20170201-raw_user_activity.json | shards=63 | written=63,000,000 | elapsed=4.1m\n",
      "[01] 2025-12-28 23:49:39 | 20160801-20170201-raw_user_activity.json | shards=64 | written=64,000,000 | elapsed=4.1m\n",
      "[01] 2025-12-28 23:49:45 | 20160801-20170201-raw_user_activity.json | shards=65 | written=65,000,000 | elapsed=4.2m\n",
      "[01] 2025-12-28 23:49:46 | DONE 20160801-20170201-raw_user_activity.json | shards=66 | total_written=65,795,428 | elapsed=4.3m\n",
      "[01] 2025-12-28 23:49:49 | 20170201-20170801-raw_user_activity.json | shards=1 | written=1,000,000 | elapsed=0.0m\n",
      "[01] 2025-12-28 23:49:53 | 20170201-20170801-raw_user_activity.json | shards=2 | written=2,000,000 | elapsed=0.1m\n",
      "[01] 2025-12-28 23:49:59 | 20170201-20170801-raw_user_activity.json | shards=3 | written=3,000,000 | elapsed=0.2m\n",
      "[01] 2025-12-28 23:50:01 | 20170201-20170801-raw_user_activity.json | shards=4 | written=4,000,000 | elapsed=0.2m\n",
      "[01] 2025-12-28 23:50:05 | 20170201-20170801-raw_user_activity.json | shards=5 | written=5,000,000 | elapsed=0.3m\n",
      "[01] 2025-12-28 23:50:09 | 20170201-20170801-raw_user_activity.json | shards=6 | written=6,000,000 | elapsed=0.4m\n",
      "[01] 2025-12-28 23:50:12 | 20170201-20170801-raw_user_activity.json | shards=7 | written=7,000,000 | elapsed=0.4m\n",
      "[01] 2025-12-28 23:50:18 | 20170201-20170801-raw_user_activity.json | shards=8 | written=8,000,000 | elapsed=0.5m\n",
      "[01] 2025-12-28 23:50:21 | 20170201-20170801-raw_user_activity.json | shards=9 | written=9,000,000 | elapsed=0.6m\n",
      "[01] 2025-12-28 23:50:27 | 20170201-20170801-raw_user_activity.json | shards=10 | written=10,000,000 | elapsed=0.7m\n",
      "[01] 2025-12-28 23:50:30 | 20170201-20170801-raw_user_activity.json | shards=11 | written=11,000,000 | elapsed=0.7m\n",
      "[01] 2025-12-28 23:50:33 | 20170201-20170801-raw_user_activity.json | shards=12 | written=12,000,000 | elapsed=0.8m\n",
      "[01] 2025-12-28 23:50:38 | 20170201-20170801-raw_user_activity.json | shards=13 | written=13,000,000 | elapsed=0.9m\n",
      "[01] 2025-12-28 23:50:41 | 20170201-20170801-raw_user_activity.json | shards=14 | written=14,000,000 | elapsed=0.9m\n",
      "[01] 2025-12-28 23:50:47 | 20170201-20170801-raw_user_activity.json | shards=15 | written=15,000,000 | elapsed=1.0m\n",
      "[01] 2025-12-28 23:50:49 | 20170201-20170801-raw_user_activity.json | shards=16 | written=16,000,000 | elapsed=1.0m\n",
      "[01] 2025-12-28 23:50:52 | 20170201-20170801-raw_user_activity.json | shards=17 | written=17,000,000 | elapsed=1.1m\n",
      "[01] 2025-12-28 23:50:57 | 20170201-20170801-raw_user_activity.json | shards=18 | written=18,000,000 | elapsed=1.2m\n",
      "[01] 2025-12-28 23:51:01 | 20170201-20170801-raw_user_activity.json | shards=19 | written=19,000,000 | elapsed=1.2m\n",
      "[01] 2025-12-28 23:51:06 | 20170201-20170801-raw_user_activity.json | shards=20 | written=20,000,000 | elapsed=1.3m\n",
      "[01] 2025-12-28 23:51:09 | 20170201-20170801-raw_user_activity.json | shards=21 | written=21,000,000 | elapsed=1.4m\n",
      "[01] 2025-12-28 23:51:12 | 20170201-20170801-raw_user_activity.json | shards=22 | written=22,000,000 | elapsed=1.4m\n",
      "[01] 2025-12-28 23:51:17 | 20170201-20170801-raw_user_activity.json | shards=23 | written=23,000,000 | elapsed=1.5m\n",
      "[01] 2025-12-28 23:51:21 | 20170201-20170801-raw_user_activity.json | shards=24 | written=24,000,000 | elapsed=1.6m\n",
      "[01] 2025-12-28 23:51:24 | 20170201-20170801-raw_user_activity.json | shards=25 | written=25,000,000 | elapsed=1.6m\n",
      "[01] 2025-12-28 23:51:29 | 20170201-20170801-raw_user_activity.json | shards=26 | written=26,000,000 | elapsed=1.7m\n",
      "[01] 2025-12-28 23:51:32 | 20170201-20170801-raw_user_activity.json | shards=27 | written=27,000,000 | elapsed=1.8m\n",
      "[01] 2025-12-28 23:51:37 | 20170201-20170801-raw_user_activity.json | shards=28 | written=28,000,000 | elapsed=1.8m\n",
      "[01] 2025-12-28 23:51:40 | 20170201-20170801-raw_user_activity.json | shards=29 | written=29,000,000 | elapsed=1.9m\n",
      "[01] 2025-12-28 23:51:43 | 20170201-20170801-raw_user_activity.json | shards=30 | written=30,000,000 | elapsed=1.9m\n",
      "[01] 2025-12-28 23:51:48 | 20170201-20170801-raw_user_activity.json | shards=31 | written=31,000,000 | elapsed=2.0m\n",
      "[01] 2025-12-28 23:51:51 | 20170201-20170801-raw_user_activity.json | shards=32 | written=32,000,000 | elapsed=2.1m\n",
      "[01] 2025-12-28 23:51:57 | 20170201-20170801-raw_user_activity.json | shards=33 | written=33,000,000 | elapsed=2.2m\n",
      "[01] 2025-12-28 23:52:00 | 20170201-20170801-raw_user_activity.json | shards=34 | written=34,000,000 | elapsed=2.2m\n",
      "[01] 2025-12-28 23:52:03 | 20170201-20170801-raw_user_activity.json | shards=35 | written=35,000,000 | elapsed=2.3m\n",
      "[01] 2025-12-28 23:52:09 | 20170201-20170801-raw_user_activity.json | shards=36 | written=36,000,000 | elapsed=2.4m\n",
      "[01] 2025-12-28 23:52:12 | 20170201-20170801-raw_user_activity.json | shards=37 | written=37,000,000 | elapsed=2.4m\n",
      "[01] 2025-12-28 23:52:17 | 20170201-20170801-raw_user_activity.json | shards=38 | written=38,000,000 | elapsed=2.5m\n",
      "[01] 2025-12-28 23:52:22 | 20170201-20170801-raw_user_activity.json | shards=39 | written=39,000,000 | elapsed=2.6m\n",
      "[01] 2025-12-28 23:52:27 | 20170201-20170801-raw_user_activity.json | shards=40 | written=40,000,000 | elapsed=2.7m\n",
      "[01] 2025-12-28 23:52:29 | 20170201-20170801-raw_user_activity.json | shards=41 | written=41,000,000 | elapsed=2.7m\n",
      "[01] 2025-12-28 23:52:32 | 20170201-20170801-raw_user_activity.json | shards=42 | written=42,000,000 | elapsed=2.8m\n",
      "[01] 2025-12-28 23:52:35 | 20170201-20170801-raw_user_activity.json | shards=43 | written=43,000,000 | elapsed=2.8m\n",
      "[01] 2025-12-28 23:52:40 | 20170201-20170801-raw_user_activity.json | shards=44 | written=44,000,000 | elapsed=2.9m\n",
      "[01] 2025-12-28 23:52:44 | 20170201-20170801-raw_user_activity.json | shards=45 | written=45,000,000 | elapsed=3.0m\n",
      "[01] 2025-12-28 23:52:48 | 20170201-20170801-raw_user_activity.json | shards=46 | written=46,000,000 | elapsed=3.0m\n",
      "[01] 2025-12-28 23:52:51 | 20170201-20170801-raw_user_activity.json | shards=47 | written=47,000,000 | elapsed=3.1m\n",
      "[01] 2025-12-28 23:52:54 | 20170201-20170801-raw_user_activity.json | shards=48 | written=48,000,000 | elapsed=3.1m\n",
      "[01] 2025-12-28 23:52:58 | 20170201-20170801-raw_user_activity.json | shards=49 | written=49,000,000 | elapsed=3.2m\n",
      "[01] 2025-12-28 23:53:02 | 20170201-20170801-raw_user_activity.json | shards=50 | written=50,000,000 | elapsed=3.3m\n",
      "[01] 2025-12-28 23:53:07 | 20170201-20170801-raw_user_activity.json | shards=51 | written=51,000,000 | elapsed=3.3m\n",
      "[01] 2025-12-28 23:53:10 | 20170201-20170801-raw_user_activity.json | shards=52 | written=52,000,000 | elapsed=3.4m\n",
      "[01] 2025-12-28 23:53:13 | 20170201-20170801-raw_user_activity.json | shards=53 | written=53,000,000 | elapsed=3.4m\n",
      "[01] 2025-12-28 23:53:18 | 20170201-20170801-raw_user_activity.json | shards=54 | written=54,000,000 | elapsed=3.5m\n",
      "[01] 2025-12-28 23:53:22 | 20170201-20170801-raw_user_activity.json | shards=55 | written=55,000,000 | elapsed=3.6m\n",
      "[01] 2025-12-28 23:53:24 | 20170201-20170801-raw_user_activity.json | shards=56 | written=56,000,000 | elapsed=3.6m\n",
      "[01] 2025-12-28 23:53:29 | DONE 20170201-20170801-raw_user_activity.json | shards=57 | total_written=56,985,474 | elapsed=3.7m\n",
      "\n",
      "Conversion summary:\n",
      "- 20150801-20151101-raw_user_activity.json: rows=43,818,789 shards=44\n",
      "- 20151101-20160201-raw_user_activity.json: rows=59,430,567 shards=60\n",
      "- 20160201-20160501-raw_user_activity.json: rows=63,745,152 shards=64\n",
      "- 20160501-20160801-raw_user_activity.json: rows=61,676,966 shards=62\n",
      "- 20160801-20170201-raw_user_activity.json: rows=65,795,428 shards=66\n",
      "- 20170201-20170801-raw_user_activity.json: rows=56,985,474 shards=57\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-09] Stream parse -> Parquet shards (one-time conversion)\n",
    "\n",
    "OUT_DIR = (REPO_ROOT / \"data\" / \"processed\" / \"xuetangx_events_parquet\").resolve()\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "log(f\"OUT_DIR: {OUT_DIR}\")\n",
    "\n",
    "def write_shard(rows, shard_path: Path):\n",
    "    df = pd.DataFrame(rows, columns=[\"course_id\", \"user_id\", \"object_id\", \"action\", \"ts\"])\n",
    "    df[\"ts\"] = pd.to_datetime(df[\"ts\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"course_id\", \"user_id\", \"action\", \"ts\"])\n",
    "    table = pa.Table.from_pandas(df, preserve_index=False)\n",
    "    pq.write_table(table, shard_path)\n",
    "    return len(df)\n",
    "\n",
    "def convert_file_to_parquet_shards(path: Path, shard_rows=1_000_000, max_blocks=None):\n",
    "    shard_idx = 0\n",
    "    buf = []\n",
    "    total_written = 0\n",
    "    blocks = 0\n",
    "\n",
    "    t0 = time.time()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for blk in ijson.items(f, \"item\"):\n",
    "            blocks += 1\n",
    "            if max_blocks and blocks > max_blocks:\n",
    "                break\n",
    "\n",
    "            if not (isinstance(blk, list) and len(blk) == 2):\n",
    "                continue\n",
    "            course_id, user_map = blk[0], blk[1]\n",
    "            if not (isinstance(course_id, str) and isinstance(user_map, dict)):\n",
    "                continue\n",
    "\n",
    "            for user_id, obj_map in user_map.items():\n",
    "                if not isinstance(obj_map, dict):\n",
    "                    continue\n",
    "                for object_id, evs in obj_map.items():\n",
    "                    if not isinstance(evs, list):\n",
    "                        continue\n",
    "                    for ev in evs:\n",
    "                        if not (isinstance(ev, list) and len(ev) == 2):\n",
    "                            continue\n",
    "                        action, ts = ev[0], ev[1]\n",
    "                        buf.append([course_id, str(user_id), str(object_id), str(action), ts])\n",
    "\n",
    "                        if len(buf) >= shard_rows:\n",
    "                            shard_path = OUT_DIR / f\"{path.stem}_shard_{shard_idx:04d}.parquet\"\n",
    "                            n = write_shard(buf, shard_path)\n",
    "                            total_written += n\n",
    "                            buf = []\n",
    "                            shard_idx += 1\n",
    "\n",
    "                            elapsed = time.time() - t0\n",
    "                            log(f\"{path.name} | shards={shard_idx} | written={total_written:,} | elapsed={elapsed/60:.1f}m\")\n",
    "\n",
    "    if buf:\n",
    "        shard_path = OUT_DIR / f\"{path.stem}_shard_{shard_idx:04d}.parquet\"\n",
    "        n = write_shard(buf, shard_path)\n",
    "        total_written += n\n",
    "        shard_idx += 1\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    log(f\"DONE {path.name} | shards={shard_idx} | total_written={total_written:,} | elapsed={elapsed/60:.1f}m\")\n",
    "    return total_written, shard_idx\n",
    "\n",
    "# Recommended: run one file first to validate, then run all.\n",
    "# 1) Validate on first file:\n",
    "# convert_file_to_parquet_shards(json_files[0], shard_rows=1_000_000)\n",
    "\n",
    "# 2) After validation, convert all:\n",
    "totals = []\n",
    "for p in json_files:\n",
    "    total_written, n_shards = convert_file_to_parquet_shards(p, shard_rows=1_000_000)\n",
    "    totals.append((p.name, total_written, n_shards))\n",
    "\n",
    "print(\"\\nConversion summary:\")\n",
    "for name, rows_written, shards in totals:\n",
    "    print(f\"- {name}: rows={rows_written:,} shards={shards}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3001a52b",
   "metadata": {},
   "source": [
    "DuckDB EDA on Parquet (fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7069930a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] 2025-12-28 23:55:49 | Reading Parquet via DuckDB: D:\\00_DS-ML-Workspace\\mooc-coldstart-session-meta\\data\\processed\\xuetangx_events_parquet\\*.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b47f28f07248f880edf54f50c4e2fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 351452376\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b351bb29b820456da8deae40a5219e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 772887\n",
      "Courses: 1629\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9e73ef103b498a8f916747e2bb98fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects: 2937678\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c65cb66a48441aac3ccde09ec33624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time range: (datetime.datetime(2015, 7, 31, 23, 59, 14), datetime.datetime(2017, 7, 31, 23, 59, 10))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fc68fd5fe74b14a02a49d8740b79ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stop_video</td>\n",
       "      <td>64090652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pause_video</td>\n",
       "      <td>57140305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>click_courseware</td>\n",
       "      <td>44017420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>play_video</td>\n",
       "      <td>43325389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seek_video</td>\n",
       "      <td>27074548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>problem_get</td>\n",
       "      <td>24958594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>load_video</td>\n",
       "      <td>24354867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>close_courseware</td>\n",
       "      <td>20505645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>click_about</td>\n",
       "      <td>9709480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>problem_check</td>\n",
       "      <td>9422514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>click_info</td>\n",
       "      <td>8353910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>problem_check_correct</td>\n",
       "      <td>7239205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>problem_check_incorrect</td>\n",
       "      <td>4157189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>problem_save</td>\n",
       "      <td>2800293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>click_progress</td>\n",
       "      <td>2084971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>click_forum</td>\n",
       "      <td>1591403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reset_problem</td>\n",
       "      <td>358664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>create_comment</td>\n",
       "      <td>219382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>create_thread</td>\n",
       "      <td>41089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>delete_comment</td>\n",
       "      <td>4838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>delete_thread</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>close_forum</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>close_info</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     action         n\n",
       "0                stop_video  64090652\n",
       "1               pause_video  57140305\n",
       "2          click_courseware  44017420\n",
       "3                play_video  43325389\n",
       "4                seek_video  27074548\n",
       "5               problem_get  24958594\n",
       "6                load_video  24354867\n",
       "7          close_courseware  20505645\n",
       "8               click_about   9709480\n",
       "9             problem_check   9422514\n",
       "10               click_info   8353910\n",
       "11    problem_check_correct   7239205\n",
       "12  problem_check_incorrect   4157189\n",
       "13             problem_save   2800293\n",
       "14           click_progress   2084971\n",
       "15              click_forum   1591403\n",
       "16            reset_problem    358664\n",
       "17           create_comment    219382\n",
       "18            create_thread     41089\n",
       "19           delete_comment      4838\n",
       "20            delete_thread      1986\n",
       "21              close_forum        30\n",
       "22               close_info         2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quantiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[33, 1017, 6331]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          quantiles\n",
       "0  [33, 1017, 6331]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [CELL 01-10] DuckDB EDA on Parquet shards\n",
    "\n",
    "PARQUET_GLOB = str(OUT_DIR / \"*.parquet\")\n",
    "log(f\"Reading Parquet via DuckDB: {PARQUET_GLOB}\")\n",
    "\n",
    "con = duckdb.connect(database=\":memory:\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE VIEW events AS\n",
    "SELECT * FROM read_parquet('{PARQUET_GLOB}');\n",
    "\"\"\")\n",
    "\n",
    "# Basic counts\n",
    "print(\"Rows:\", con.execute(\"SELECT COUNT(*) FROM events\").fetchone()[0])\n",
    "print(\"Users:\", con.execute(\"SELECT COUNT(DISTINCT user_id) FROM events\").fetchone()[0])\n",
    "print(\"Courses:\", con.execute(\"SELECT COUNT(DISTINCT course_id) FROM events\").fetchone()[0])\n",
    "print(\"Objects:\", con.execute(\"SELECT COUNT(DISTINCT object_id) FROM events\").fetchone()[0])\n",
    "\n",
    "# Time range\n",
    "print(\"Time range:\", con.execute(\"SELECT MIN(ts), MAX(ts) FROM events\").fetchone())\n",
    "\n",
    "# Top actions\n",
    "df_top_actions = con.execute(\"\"\"\n",
    "SELECT action, COUNT(*) AS n\n",
    "FROM events\n",
    "GROUP BY action\n",
    "ORDER BY n DESC\n",
    "LIMIT 30\n",
    "\"\"\").df()\n",
    "display(df_top_actions)\n",
    "\n",
    "# Per-user event count distribution (quick)\n",
    "df_user_dist = con.execute(\"\"\"\n",
    "SELECT\n",
    "  approx_quantile(cnt, [0.5, 0.9, 0.99]) AS quantiles\n",
    "FROM (\n",
    "  SELECT user_id, COUNT(*) cnt\n",
    "  FROM events\n",
    "  GROUP BY user_id\n",
    ");\n",
    "\"\"\").df()\n",
    "display(df_user_dist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c77d8b3",
   "metadata": {},
   "source": [
    "Decide interaction “item_id” + export interactions (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81e942ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b033761b5024622b7b8c8e2bbded99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] 2025-12-29 00:00:47 | Wrote interactions parquet: D:\\00_DS-ML-Workspace\\mooc-coldstart-session-meta\\data\\processed\\xuetangx_interactions_course.parquet\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-11] Build interactions table (choose item granularity)\n",
    "\n",
    "ITEM_MODE = \"course\"  # \"course\" or \"object\"\n",
    "\n",
    "if ITEM_MODE == \"course\":\n",
    "    item_col = \"course_id\"\n",
    "elif ITEM_MODE == \"object\":\n",
    "    item_col = \"object_id\"\n",
    "else:\n",
    "    raise ValueError(\"ITEM_MODE must be 'course' or 'object'\")\n",
    "\n",
    "# Keep only actions you consider as interactions (optional)\n",
    "# Leave as None to keep all.\n",
    "KEEP_ACTIONS = None  # e.g. {\"click_courseware\",\"play_video\",\"problem_check\",\"click_forum\"}\n",
    "\n",
    "where = \"\"\n",
    "if KEEP_ACTIONS:\n",
    "    actions_list = \",\".join([f\"'{a}'\" for a in sorted(KEEP_ACTIONS)])\n",
    "    where = f\"WHERE action IN ({actions_list})\"\n",
    "\n",
    "inter_path = (REPO_ROOT / \"data\" / \"processed\" / f\"xuetangx_interactions_{ITEM_MODE}.parquet\").resolve()\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "COPY (\n",
    "  SELECT\n",
    "    user_id,\n",
    "    {item_col} AS item_id,\n",
    "    ts,\n",
    "    action,\n",
    "    course_id\n",
    "  FROM events\n",
    "  {where}\n",
    ") TO '{str(inter_path)}' (FORMAT PARQUET);\n",
    "\"\"\")\n",
    "\n",
    "log(f\"Wrote interactions parquet: {inter_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5698d0ec",
   "metadata": {},
   "source": [
    "Reports folder + run metadata + save core summary tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26b0dca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] 2025-12-29 01:30:02 | REPORT OUT: D:\\00_DS-ML-Workspace\\mooc-coldstart-session-meta\\reports\\01_eda_source_mooc\\20251229_013002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6962919155c4d6ca11ddf8699aa9acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e573311c2878435184ad5080b914d70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_events</th>\n",
       "      <th>n_users</th>\n",
       "      <th>n_courses</th>\n",
       "      <th>n_objects</th>\n",
       "      <th>min_ts</th>\n",
       "      <th>max_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>351452376</td>\n",
       "      <td>772887</td>\n",
       "      <td>1629</td>\n",
       "      <td>2937678</td>\n",
       "      <td>2015-07-31 23:59:14</td>\n",
       "      <td>2017-07-31 23:59:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_events  n_users  n_courses  n_objects              min_ts  \\\n",
       "0  351452376   772887       1629    2937678 2015-07-31 23:59:14   \n",
       "\n",
       "               max_ts  \n",
       "0 2017-07-31 23:59:10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stop_video</td>\n",
       "      <td>64090652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pause_video</td>\n",
       "      <td>57140305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>click_courseware</td>\n",
       "      <td>44017420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>play_video</td>\n",
       "      <td>43325389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seek_video</td>\n",
       "      <td>27074548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>problem_get</td>\n",
       "      <td>24958594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>load_video</td>\n",
       "      <td>24354867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>close_courseware</td>\n",
       "      <td>20505645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>click_about</td>\n",
       "      <td>9709480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>problem_check</td>\n",
       "      <td>9422514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>click_info</td>\n",
       "      <td>8353910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>problem_check_correct</td>\n",
       "      <td>7239205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>problem_check_incorrect</td>\n",
       "      <td>4157189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>problem_save</td>\n",
       "      <td>2800293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>click_progress</td>\n",
       "      <td>2084971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>click_forum</td>\n",
       "      <td>1591403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reset_problem</td>\n",
       "      <td>358664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>create_comment</td>\n",
       "      <td>219382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>create_thread</td>\n",
       "      <td>41089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>delete_comment</td>\n",
       "      <td>4838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     action         n\n",
       "0                stop_video  64090652\n",
       "1               pause_video  57140305\n",
       "2          click_courseware  44017420\n",
       "3                play_video  43325389\n",
       "4                seek_video  27074548\n",
       "5               problem_get  24958594\n",
       "6                load_video  24354867\n",
       "7          close_courseware  20505645\n",
       "8               click_about   9709480\n",
       "9             problem_check   9422514\n",
       "10               click_info   8353910\n",
       "11    problem_check_correct   7239205\n",
       "12  problem_check_incorrect   4157189\n",
       "13             problem_save   2800293\n",
       "14           click_progress   2084971\n",
       "15              click_forum   1591403\n",
       "16            reset_problem    358664\n",
       "17           create_comment    219382\n",
       "18            create_thread     41089\n",
       "19           delete_comment      4838"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_events_per_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[33, 1022, 6352]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  q_events_per_user\n",
       "0  [33, 1022, 6352]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] 2025-12-29 01:30:57 | Saved core EDA tables to reports folder.\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-12] Reports: folder + metadata + save core summary tables\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "REPORT_DIR = (REPO_ROOT / \"reports\" / \"01_eda_source_mooc\").resolve()\n",
    "RUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUT = (REPORT_DIR / RUN_TAG)\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "log(f\"REPORT OUT: {OUT}\")\n",
    "\n",
    "# Save a small \"run metadata\" json\n",
    "meta = {\n",
    "    \"run_tag\": RUN_TAG,\n",
    "    \"source_dir\": str(SOURCE_DIR),\n",
    "    \"events_parquet_glob\": str(OUT_DIR / \"*.parquet\"),\n",
    "    \"filtered_interactions_parquet\": str(REPO_ROOT / \"data\" / \"processed\" / \"xuetangx_interactions_course_filtered.parquet\"),\n",
    "}\n",
    "\n",
    "with open(OUT / \"run_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "# Core EDA tables (small) from DuckDB\n",
    "df_counts = con.execute(\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS n_events,\n",
    "  COUNT(DISTINCT user_id) AS n_users,\n",
    "  COUNT(DISTINCT course_id) AS n_courses,\n",
    "  COUNT(DISTINCT object_id) AS n_objects,\n",
    "  MIN(ts) AS min_ts,\n",
    "  MAX(ts) AS max_ts\n",
    "FROM events;\n",
    "\"\"\").df()\n",
    "\n",
    "df_top_actions = con.execute(\"\"\"\n",
    "SELECT action, COUNT(*) AS n\n",
    "FROM events\n",
    "GROUP BY action\n",
    "ORDER BY n DESC\n",
    "LIMIT 50;\n",
    "\"\"\").df()\n",
    "\n",
    "df_user_quant = con.execute(\"\"\"\n",
    "SELECT approx_quantile(cnt, [0.5, 0.9, 0.99]) AS q_events_per_user\n",
    "FROM (\n",
    "  SELECT user_id, COUNT(*) cnt\n",
    "  FROM events\n",
    "  GROUP BY user_id\n",
    ");\n",
    "\"\"\").df()\n",
    "\n",
    "display(df_counts)\n",
    "display(df_top_actions.head(20))\n",
    "display(df_user_quant)\n",
    "\n",
    "# Save to CSV for the report folder\n",
    "df_counts.to_csv(OUT / \"counts_overview.csv\", index=False)\n",
    "df_top_actions.to_csv(OUT / \"top_actions.csv\", index=False)\n",
    "df_user_quant.to_csv(OUT / \"user_event_quantiles.csv\", index=False)\n",
    "\n",
    "log(\"Saved core EDA tables to reports folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a407b4",
   "metadata": {},
   "source": [
    "Plot: Top actions bar chart (save PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e4a160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 01-13] Plot: Top actions (save)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "topN = 20\n",
    "dfp = df_top_actions.head(topN).copy()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(dfp[\"action\"][::-1], dfp[\"n\"][::-1])\n",
    "plt.xlabel(\"Event count\")\n",
    "plt.title(f\"Top {topN} actions (XuetangX raw events)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "png = OUT / f\"plot_top_{topN}_actions.png\"\n",
    "plt.savefig(png, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "log(f\"Saved: {png}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741d326b",
   "metadata": {},
   "source": [
    "Plot: Events over time (daily) from DuckDB (fast) + save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 01-14] Plot: Daily event volume (fast via DuckDB aggregation)\n",
    "\n",
    "df_daily = con.execute(\"\"\"\n",
    "SELECT\n",
    "  DATE_TRUNC('day', ts) AS day,\n",
    "  COUNT(*) AS n\n",
    "FROM events\n",
    "GROUP BY day\n",
    "ORDER BY day;\n",
    "\"\"\").df()\n",
    "\n",
    "display(df_daily.head())\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(df_daily[\"day\"], df_daily[\"n\"])\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Events\")\n",
    "plt.title(\"Daily event volume (raw XuetangX)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "png = OUT / \"plot_daily_event_volume.png\"\n",
    "plt.savefig(png, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "df_daily.to_csv(OUT / \"daily_event_volume.csv\", index=False)\n",
    "log(f\"Saved: {png}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599eb8e9",
   "metadata": {},
   "source": [
    "Plot: Course popularity (top 50 courses by events) + save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e0b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 01-15] Plot: Course popularity (top courses by event count)\n",
    "\n",
    "df_course_top = con.execute(\"\"\"\n",
    "SELECT course_id, COUNT(*) AS n\n",
    "FROM events\n",
    "GROUP BY course_id\n",
    "ORDER BY n DESC\n",
    "LIMIT 50;\n",
    "\"\"\").df()\n",
    "\n",
    "display(df_course_top.head())\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(df_course_top[\"course_id\"][::-1], df_course_top[\"n\"][::-1])\n",
    "plt.xlabel(\"Event count\")\n",
    "plt.title(\"Top 50 courses by event count\")\n",
    "plt.tight_layout()\n",
    "\n",
    "png = OUT / \"plot_top_50_courses.png\"\n",
    "plt.savefig(png, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "df_course_top.to_csv(OUT / \"top_50_courses.csv\", index=False)\n",
    "log(f\"Saved: {png}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82f62dd",
   "metadata": {},
   "source": [
    "Plot: User activity distribution (log-scale histogram) + save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa2f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 01-16] Plot: User activity distribution (histogram of events per user)\n",
    "\n",
    "# Pull a manageable sample of per-user counts (DuckDB computes it; result is large but still feasible)\n",
    "# If memory is a concern, add a LIMIT sample; but start with full aggregation.\n",
    "df_user_counts = con.execute(\"\"\"\n",
    "SELECT user_id, COUNT(*) AS n\n",
    "FROM events\n",
    "GROUP BY user_id;\n",
    "\"\"\").df()\n",
    "\n",
    "display(df_user_counts.head())\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(df_user_counts[\"n\"], bins=200, log=True)\n",
    "plt.xlabel(\"Events per user\")\n",
    "plt.ylabel(\"Frequency (log)\")\n",
    "plt.title(\"User activity distribution (events per user)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "png = OUT / \"plot_user_events_hist_log.png\"\n",
    "plt.savefig(png, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# Save quantiles (small) + optionally a downsample\n",
    "df_user_counts[\"n\"].describe(percentiles=[0.5,0.9,0.99]).to_csv(OUT / \"user_events_describe.csv\")\n",
    "log(f\"Saved: {png}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a3aab2",
   "metadata": {},
   "source": [
    "Write a short Markdown report (auto) into reports folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0891308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 01-17] Create a short Markdown summary report\n",
    "\n",
    "md = []\n",
    "md.append(f\"# 01 — EDA Source MOOC (XuetangX) — {RUN_TAG}\\n\")\n",
    "md.append(\"## Inputs\\n\")\n",
    "md.append(f\"- Raw folder: `{SOURCE_DIR}`\\n\")\n",
    "md.append(f\"- Parquet shards: `{OUT_DIR}/*.parquet`\\n\")\n",
    "md.append(\"\\n## Overview counts\\n\")\n",
    "md.append(df_counts.to_markdown(index=False))\n",
    "md.append(\"\\n\\n## Top actions (first 20)\\n\")\n",
    "md.append(df_top_actions.head(20).to_markdown(index=False))\n",
    "md.append(\"\\n\\n## User event count quantiles\\n\")\n",
    "md.append(df_user_quant.to_markdown(index=False))\n",
    "md.append(\"\\n\\n## Saved figures\\n\")\n",
    "md.append(\"- plot_top_20_actions.png\\n\")\n",
    "md.append(\"- plot_daily_event_volume.png\\n\")\n",
    "md.append(\"- plot_top_50_courses.png\\n\")\n",
    "md.append(\"- plot_user_events_hist_log.png\\n\")\n",
    "\n",
    "report_path = OUT / \"report_01_eda_source_mooc.md\"\n",
    "report_path.write_text(\"\\n\".join(md), encoding=\"utf-8\")\n",
    "log(f\"Wrote report: {report_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebbd83d",
   "metadata": {},
   "source": [
    "Plot: Top actions (save PNG + CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b863b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 01-14] Plot: Top actions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_top = con.execute(\"\"\"\n",
    "SELECT action, COUNT(*) AS n\n",
    "FROM events\n",
    "GROUP BY action\n",
    "ORDER BY n DESC\n",
    "LIMIT 20;\n",
    "\"\"\").df()\n",
    "\n",
    "df_top.to_csv(OUT / \"top_actions_top20.csv\", index=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(df_top[\"action\"][::-1], df_top[\"n\"][::-1])\n",
    "plt.xlabel(\"Event count\")\n",
    "plt.title(\"Top 20 actions (XuetangX raw events)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "png = OUT / \"plot_top20_actions.png\"\n",
    "plt.savefig(png, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "log(f\"Saved: {png}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917388c4",
   "metadata": {},
   "source": [
    "Plot: Daily event volume (save PNG + CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b8220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 01-15] Plot: Daily event volume\n",
    "\n",
    "df_daily = con.execute(\"\"\"\n",
    "SELECT DATE_TRUNC('day', ts) AS day, COUNT(*) AS n\n",
    "FROM events\n",
    "GROUP BY day\n",
    "ORDER BY day;\n",
    "\"\"\").df()\n",
    "\n",
    "df_daily.to_csv(OUT / \"daily_event_volume.csv\", index=False)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(df_daily[\"day\"], df_daily[\"n\"])\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Events\")\n",
    "plt.title(\"Daily event volume (XuetangX raw events)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "png = OUT / \"plot_daily_event_volume.png\"\n",
    "plt.savefig(png, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "log(f\"Saved: {png}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b28db5",
   "metadata": {},
   "source": [
    "Plot: User activity distribution (binned in DuckDB, log-friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab7c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 01-16] Plot: User activity distribution (log10 bins)\n",
    "\n",
    "df_bins = con.execute(\"\"\"\n",
    "WITH u AS (\n",
    "  SELECT user_id, COUNT(*) AS cnt\n",
    "  FROM events\n",
    "  GROUP BY user_id\n",
    "),\n",
    "b AS (\n",
    "  SELECT\n",
    "    CAST(FLOOR(LOG10(cnt)) AS INTEGER) AS log10_bin,\n",
    "    COUNT(*) AS n_users\n",
    "  FROM u\n",
    "  GROUP BY log10_bin\n",
    ")\n",
    "SELECT * FROM b\n",
    "ORDER BY log10_bin;\n",
    "\"\"\").df()\n",
    "\n",
    "df_bins.to_csv(OUT / \"user_activity_log10_bins.csv\", index=False)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(df_bins[\"log10_bin\"], df_bins[\"n_users\"])\n",
    "plt.xlabel(\"log10(events per user) bin\")\n",
    "plt.ylabel(\"Number of users\")\n",
    "plt.title(\"User activity distribution (binned by log10)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "png = OUT / \"plot_user_activity_log10_bins.png\"\n",
    "plt.savefig(png, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "log(f\"Saved: {png}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b786f6c2",
   "metadata": {},
   "source": [
    "Plot: Top courses by event count (save PNG + CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94637f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 01-17] Plot: Top 20 courses by event count\n",
    "\n",
    "df_courses = con.execute(\"\"\"\n",
    "SELECT course_id, COUNT(*) AS n\n",
    "FROM events\n",
    "GROUP BY course_id\n",
    "ORDER BY n DESC\n",
    "LIMIT 20;\n",
    "\"\"\").df()\n",
    "\n",
    "df_courses.to_csv(OUT / \"top_courses_top20.csv\", index=False)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.barh(df_courses[\"course_id\"][::-1], df_courses[\"n\"][::-1])\n",
    "plt.xlabel(\"Event count\")\n",
    "plt.title(\"Top 20 courses by event count\")\n",
    "plt.tight_layout()\n",
    "\n",
    "png = OUT / \"plot_top20_courses.png\"\n",
    "plt.savefig(png, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "log(f\"Saved: {png}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4048b29",
   "metadata": {},
   "source": [
    "Write a short Markdown report file (so Notebook 01 produces an artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d890a9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 01-18] Write Markdown report\n",
    "\n",
    "df_counts = con.execute(\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS n_events,\n",
    "  COUNT(DISTINCT user_id) AS n_users,\n",
    "  COUNT(DISTINCT course_id) AS n_courses,\n",
    "  COUNT(DISTINCT object_id) AS n_objects,\n",
    "  MIN(ts) AS min_ts,\n",
    "  MAX(ts) AS max_ts\n",
    "FROM events;\n",
    "\"\"\").df()\n",
    "\n",
    "md = []\n",
    "md.append(f\"# 01 — EDA Source MOOC (XuetangX raw) — {RUN_TAG}\\n\")\n",
    "md.append(\"## Overview\\n\")\n",
    "md.append(df_counts.to_markdown(index=False))\n",
    "md.append(\"\\n\\n## Artifacts\\n\")\n",
    "md.append(\"- dataset_metadata.json (also saved under data/processed/...)\\n\")\n",
    "md.append(\"- plot_top20_actions.png\\n\")\n",
    "md.append(\"- plot_daily_event_volume.png\\n\")\n",
    "md.append(\"- plot_user_activity_log10_bins.png\\n\")\n",
    "md.append(\"- plot_top20_courses.png\\n\")\n",
    "\n",
    "report_path = OUT / \"report_01_eda_source_mooc.md\"\n",
    "report_path.write_text(\"\\n\".join(md), encoding=\"utf-8\")\n",
    "log(f\"Wrote: {report_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26cb919",
   "metadata": {},
   "source": [
    "Generate related plots (Matplotlib) + save to reports/01_eda_source_mooc/<RUN_TAG>/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38599655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 01-12] Reports output folder (per-run)\n",
    "\n",
    "import json\n",
    "import platform\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "REPORT_DIR = (REPO_ROOT / \"reports\" / \"01_eda_source_mooc\").resolve()\n",
    "RUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUT = REPORT_DIR / RUN_TAG\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "log(f\"REPORT OUT: {OUT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fbaa9c",
   "metadata": {},
   "source": [
    "Save dataset metadata (reproducibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "93391c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdb6367d026463b9981bede3b74ba57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] 2025-12-29 01:51:20 | Saved metadata: D:\\00_DS-ML-Workspace\\mooc-coldstart-session-meta\\data\\processed\\xuetangx_events_parquet\\dataset_metadata.json\n",
      "[01] 2025-12-29 01:51:20 | Saved metadata copy: D:\\00_DS-ML-Workspace\\mooc-coldstart-session-meta\\reports\\01_eda_source_mooc\\20251229_013002\\dataset_metadata.json\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-13] Save dataset metadata for reproducibility\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "# Raw files inventory\n",
    "raw_files = []\n",
    "for p in sorted(SOURCE_DIR.glob(\"*.json\")):\n",
    "    st = p.stat()\n",
    "    raw_files.append({\n",
    "        \"name\": p.name,\n",
    "        \"path\": str(p),\n",
    "        \"size_bytes\": int(st.st_size),\n",
    "        \"mtime\": datetime.fromtimestamp(st.st_mtime).isoformat(timespec=\"seconds\"),\n",
    "    })\n",
    "\n",
    "# Parquet shards inventory\n",
    "parquet_files = sorted(OUT_DIR.glob(\"*.parquet\"))\n",
    "parquet_total_bytes = sum(p.stat().st_size for p in parquet_files)\n",
    "\n",
    "# Core counts + time range + top actions + user quantiles from DuckDB\n",
    "counts = con.execute(\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS n_events,\n",
    "  COUNT(DISTINCT user_id) AS n_users,\n",
    "  COUNT(DISTINCT course_id) AS n_courses,\n",
    "  COUNT(DISTINCT object_id) AS n_objects,\n",
    "  MIN(ts) AS min_ts,\n",
    "  MAX(ts) AS max_ts\n",
    "FROM events;\n",
    "\"\"\").fetchone()\n",
    "\n",
    "top_actions = con.execute(\"\"\"\n",
    "SELECT action, COUNT(*) AS n\n",
    "FROM events\n",
    "GROUP BY action\n",
    "ORDER BY n DESC\n",
    "LIMIT 30;\n",
    "\"\"\").df().to_dict(orient=\"records\")\n",
    "\n",
    "user_q = con.execute(\"\"\"\n",
    "SELECT approx_quantile(cnt, [0.5, 0.9, 0.99]) AS q_events_per_user\n",
    "FROM (SELECT user_id, COUNT(*) cnt FROM events GROUP BY user_id);\n",
    "\"\"\").fetchone()[0]\n",
    "\n",
    "meta = {\n",
    "    \"generated_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"repo_root\": str(REPO_ROOT),\n",
    "    \"source_dir\": str(SOURCE_DIR),\n",
    "    \"raw_files\": raw_files,\n",
    "    \"events_parquet_dir\": str(OUT_DIR),\n",
    "    \"events_parquet_shards\": len(parquet_files),\n",
    "    \"events_parquet_total_bytes\": int(parquet_total_bytes),\n",
    "    \"duckdb_events_view\": str(OUT_DIR / \"*.parquet\"),\n",
    "    \"counts\": {\n",
    "        \"n_events\": int(counts[0]),\n",
    "        \"n_users\": int(counts[1]),\n",
    "        \"n_courses\": int(counts[2]),\n",
    "        \"n_objects\": int(counts[3]),\n",
    "        \"min_ts\": str(counts[4]),\n",
    "        \"max_ts\": str(counts[5]),\n",
    "    },\n",
    "    \"top_actions\": top_actions,\n",
    "    \"events_per_user_quantiles\": user_q,\n",
    "    \"env\": {\n",
    "        \"python\": sys.version.split()[0],\n",
    "        \"platform\": platform.platform(),\n",
    "        \"pandas\": getattr(pd, \"__version__\", \"unknown\"),\n",
    "        \"duckdb\": getattr(duckdb, \"__version__\", \"unknown\"),\n",
    "        \"pyarrow\": getattr(pa, \"__version__\", \"unknown\"),\n",
    "        \"ijson\": getattr(ijson, \"__version__\", \"unknown\"),\n",
    "    },\n",
    "    \"notes\": [\n",
    "        \"This notebook (01) covers EDA + JSON→Parquet conversion + DuckDB summaries only.\",\n",
    "        \"Session-gap analysis and sessionization are planned for notebooks 04/05.\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Save metadata to processed + reports\n",
    "meta_proc_path = (OUT_DIR / \"dataset_metadata.json\")\n",
    "meta_rep_path = (OUT / \"dataset_metadata.json\")\n",
    "\n",
    "meta_proc_path.write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n",
    "meta_rep_path.write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "log(f\"Saved metadata: {meta_proc_path}\")\n",
    "log(f\"Saved metadata copy: {meta_rep_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca80e329",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d745a34f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "519b560c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9da26c6d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "307b2da3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cc2e17d",
   "metadata": {},
   "source": [
    "Data Quality Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd491888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATA QUALITY REPORT\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d34007ac6f74ad19be0b4f1aa4c1b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null_users</th>\n",
       "      <th>null_courses</th>\n",
       "      <th>null_timestamps</th>\n",
       "      <th>null_actions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   null_users  null_courses  null_timestamps  null_actions\n",
       "0         0.0           0.0              0.0           0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da72e468befe4744bf302fd655f7c0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temporal distribution:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>events</th>\n",
       "      <th>active_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>94</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>5237094</td>\n",
       "      <td>28215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>11550102</td>\n",
       "      <td>61114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>27032075</td>\n",
       "      <td>75277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>26533170</td>\n",
       "      <td>77930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>19850262</td>\n",
       "      <td>75996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>13046764</td>\n",
       "      <td>61471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>10604181</td>\n",
       "      <td>54890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>26517475</td>\n",
       "      <td>103378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>26623544</td>\n",
       "      <td>93939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>27314302</td>\n",
       "      <td>102377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>18468708</td>\n",
       "      <td>87988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>15893822</td>\n",
       "      <td>70588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>9808402</td>\n",
       "      <td>44384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>11004241</td>\n",
       "      <td>67912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>13399500</td>\n",
       "      <td>69899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>12428143</td>\n",
       "      <td>63022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>11989677</td>\n",
       "      <td>61647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>7165434</td>\n",
       "      <td>41191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>9005508</td>\n",
       "      <td>46821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>12707803</td>\n",
       "      <td>67073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>10040615</td>\n",
       "      <td>53551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>10336191</td>\n",
       "      <td>51474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>7827866</td>\n",
       "      <td>44511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>7067403</td>\n",
       "      <td>41433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        month    events  active_users\n",
       "0  2015-07-01        94            21\n",
       "1  2015-08-01   5237094         28215\n",
       "2  2015-09-01  11550102         61114\n",
       "3  2015-10-01  27032075         75277\n",
       "4  2015-11-01  26533170         77930\n",
       "5  2015-12-01  19850262         75996\n",
       "6  2016-01-01  13046764         61471\n",
       "7  2016-02-01  10604181         54890\n",
       "8  2016-03-01  26517475        103378\n",
       "9  2016-04-01  26623544         93939\n",
       "10 2016-05-01  27314302        102377\n",
       "11 2016-06-01  18468708         87988\n",
       "12 2016-07-01  15893822         70588\n",
       "13 2016-08-01   9808402         44384\n",
       "14 2016-09-01  11004241         67912\n",
       "15 2016-10-01  13399500         69899\n",
       "16 2016-11-01  12428143         63022\n",
       "17 2016-12-01  11989677         61647\n",
       "18 2017-01-01   7165434         41191\n",
       "19 2017-02-01   9005508         46821\n",
       "20 2017-03-01  12707803         67073\n",
       "21 2017-04-01  10040615         53551\n",
       "22 2017-05-01  10336191         51474\n",
       "23 2017-06-01   7827866         44511\n",
       "24 2017-07-01   7067403         41433"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8027f6b4d62f43ed8738d531e5b5b062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Action diversity per user:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_action_diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[7, 15, 18]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  q_action_diversity\n",
       "0        [7, 15, 18]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [CELL 01-18] Data quality summary\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DATA QUALITY REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Missing values\n",
    "df_missing = con.execute(\"\"\"\n",
    "SELECT\n",
    "  SUM(CASE WHEN user_id IS NULL THEN 1 ELSE 0 END) AS null_users,\n",
    "  SUM(CASE WHEN course_id IS NULL THEN 1 ELSE 0 END) AS null_courses,\n",
    "  SUM(CASE WHEN ts IS NULL THEN 1 ELSE 0 END) AS null_timestamps,\n",
    "  SUM(CASE WHEN action IS NULL THEN 1 ELSE 0 END) AS null_actions\n",
    "FROM events;\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "display(df_missing)\n",
    "\n",
    "# Temporal coverage\n",
    "df_temporal = con.execute(\"\"\"\n",
    "SELECT\n",
    "  DATE_TRUNC('month', ts) AS month,\n",
    "  COUNT(*) AS events,\n",
    "  COUNT(DISTINCT user_id) AS active_users\n",
    "FROM events\n",
    "GROUP BY month\n",
    "ORDER BY month;\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nTemporal distribution:\")\n",
    "display(df_temporal)\n",
    "\n",
    "# Action diversity per user\n",
    "df_action_div = con.execute(\"\"\"\n",
    "WITH user_actions AS (\n",
    "  SELECT user_id, COUNT(DISTINCT action) AS n_distinct_actions\n",
    "  FROM events\n",
    "  GROUP BY user_id\n",
    ")\n",
    "SELECT\n",
    "  approx_quantile(n_distinct_actions, [0.5, 0.9, 0.99]) AS q_action_diversity\n",
    "FROM user_actions;\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nAction diversity per user:\")\n",
    "display(df_action_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cold-Start Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa780c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 01-19] Cold-start scenario analysis\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"COLD-START READINESS ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Users with <5 events (cold-start users)\n",
    "df_coldstart = con.execute(\"\"\"\n",
    "WITH user_counts AS (\n",
    "  SELECT user_id, COUNT(*) AS n_events\n",
    "  FROM events\n",
    "  GROUP BY user_id\n",
    ")\n",
    "SELECT\n",
    "  SUM(CASE WHEN n_events < 5 THEN 1 ELSE 0 END) AS users_lt_5_events,\n",
    "  SUM(CASE WHEN n_events < 10 THEN 1 ELSE 0 END) AS users_lt_10_events,\n",
    "  SUM(CASE WHEN n_events < 20 THEN 1 ELSE 0 END) AS users_lt_20_events,\n",
    "  COUNT(*) AS total_users\n",
    "FROM user_counts;\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nCold-start user distribution:\")\n",
    "display(df_coldstart)\n",
    "\n",
    "# First-session characteristics\n",
    "df_first_sess = con.execute(\"\"\"\n",
    "WITH first_sessions AS (\n",
    "  SELECT user_id, sess_idx, COUNT(*) AS sess_len\n",
    "  FROM sessioned\n",
    "  WHERE sess_idx = 1\n",
    "  GROUP BY user_id, sess_idx\n",
    ")\n",
    "SELECT\n",
    "  approx_quantile(sess_len, [0.5, 0.9, 0.99]) AS q_first_session_length\n",
    "FROM first_sessions;\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nFirst session lengths:\")\n",
    "display(df_first_sess)\n",
    "\n",
    "print(\"\\n✅ Cold-start readiness:\")\n",
    "print(\"  - If >50% users have <20 events: GOOD for cold-start research\")\n",
    "print(\"  - First session P50 >5 events: Can build initial preferences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79019d30",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e521fb33",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74a3a6dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bae59017",
   "metadata": {},
   "source": [
    "Create filtered interaction parquet (course-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a6871b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7836a0baf14b01a80e56cfd35a1c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] 2025-12-29 00:03:42 | Wrote filtered interactions parquet: D:\\00_DS-ML-Workspace\\mooc-coldstart-session-meta\\data\\processed\\xuetangx_interactions_course_filtered.parquet\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-12] Filter to meaningful interaction actions + export interactions (course-level)\n",
    "\n",
    "KEEP_ACTIONS = {\n",
    "    \"click_courseware\",\n",
    "    \"load_video\",\n",
    "    \"play_video\",\n",
    "    \"problem_get\",\n",
    "    \"problem_check\",\n",
    "    \"click_info\",\n",
    "    \"click_about\",\n",
    "    \"click_progress\",\n",
    "    \"click_forum\",\n",
    "}\n",
    "\n",
    "actions_list = \",\".join([f\"'{a}'\" for a in sorted(KEEP_ACTIONS)])\n",
    "filtered_path = (REPO_ROOT / \"data\" / \"processed\" / \"xuetangx_interactions_course_filtered.parquet\").resolve()\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "COPY (\n",
    "  SELECT\n",
    "    user_id,\n",
    "    course_id AS item_id,\n",
    "    ts,\n",
    "    action\n",
    "  FROM events\n",
    "  WHERE action IN ({actions_list})\n",
    ") TO '{str(filtered_path)}' (FORMAT PARQUET);\n",
    "\"\"\")\n",
    "\n",
    "log(f\"Wrote filtered interactions parquet: {filtered_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b7b6b",
   "metadata": {},
   "source": [
    "Sessionization EDA (time-gap sessions on filtered interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b62c1dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a832f12da3465a91557aa29db991f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_sessions</th>\n",
       "      <th>avg_len</th>\n",
       "      <th>q</th>\n",
       "      <th>max_len</th>\n",
       "      <th>sessions_ge_2</th>\n",
       "      <th>sessions_ge_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6350920</td>\n",
       "      <td>26.424289</td>\n",
       "      <td>[11, 65, 208]</td>\n",
       "      <td>131827</td>\n",
       "      <td>5488136.0</td>\n",
       "      <td>4961653.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_sessions    avg_len              q  max_len  sessions_ge_2  sessions_ge_3\n",
       "0     6350920  26.424289  [11, 65, 208]   131827      5488136.0      4961653.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [CELL 01-13] Sessionization EDA (time-gap sessions) using filtered interactions\n",
    "\n",
    "gap_minutes = 30\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE OR REPLACE VIEW inter AS\n",
    "SELECT * FROM read_parquet('{str(filtered_path)}');\n",
    "\"\"\")\n",
    "\n",
    "df_stats = con.execute(f\"\"\"\n",
    "WITH x AS (\n",
    "  SELECT\n",
    "    user_id,\n",
    "    item_id,\n",
    "    ts,\n",
    "    LAG(ts) OVER (PARTITION BY user_id ORDER BY ts) AS prev_ts\n",
    "  FROM inter\n",
    "),\n",
    "y AS (\n",
    "  SELECT\n",
    "    user_id,\n",
    "    item_id,\n",
    "    ts,\n",
    "    CASE\n",
    "      WHEN prev_ts IS NULL THEN 1\n",
    "      WHEN ts - prev_ts > INTERVAL '{gap_minutes} minutes' THEN 1\n",
    "      ELSE 0\n",
    "    END AS new_sess\n",
    "  FROM x\n",
    "),\n",
    "z AS (\n",
    "  SELECT\n",
    "    user_id,\n",
    "    item_id,\n",
    "    ts,\n",
    "    SUM(new_sess) OVER (PARTITION BY user_id ORDER BY ts ROWS UNBOUNDED PRECEDING) AS sess_idx\n",
    "  FROM y\n",
    "),\n",
    "sizes AS (\n",
    "  SELECT user_id, sess_idx, COUNT(*) AS sess_len\n",
    "  FROM z\n",
    "  GROUP BY user_id, sess_idx\n",
    ")\n",
    "SELECT\n",
    "  COUNT(*) AS n_sessions,\n",
    "  AVG(sess_len) AS avg_len,\n",
    "  approx_quantile(sess_len, [0.5, 0.9, 0.99]) AS q,\n",
    "  MAX(sess_len) AS max_len,\n",
    "  SUM(CASE WHEN sess_len >= 2 THEN 1 ELSE 0 END) AS sessions_ge_2,\n",
    "  SUM(CASE WHEN sess_len >= 3 THEN 1 ELSE 0 END) AS sessions_ge_3\n",
    "FROM sizes;\n",
    "\"\"\").df()\n",
    "\n",
    "display(df_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45dab12",
   "metadata": {},
   "source": [
    "Sequence readiness EDA (per-user unique course counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d296ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9060d807ebb64b42b2dfad45bd612661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_events</th>\n",
       "      <th>q_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[22, 542, 2927]</td>\n",
       "      <td>[2, 8, 35]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          q_events     q_items\n",
       "0  [22, 542, 2927]  [2, 8, 35]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [CELL 01-14] Sequence readiness: user unique course counts (filtered)\n",
    "\n",
    "df_user = con.execute(\"\"\"\n",
    "WITH u AS (\n",
    "  SELECT user_id, COUNT(*) AS n_events, COUNT(DISTINCT item_id) AS n_items\n",
    "  FROM inter\n",
    "  GROUP BY user_id\n",
    ")\n",
    "SELECT\n",
    "  approx_quantile(n_events, [0.5,0.9,0.99]) AS q_events,\n",
    "  approx_quantile(n_items,  [0.5,0.9,0.99]) AS q_items\n",
    "FROM u;\n",
    "\"\"\").df()\n",
    "\n",
    "display(df_user)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f585e81",
   "metadata": {},
   "source": [
    "Inspect long-session outliers and decide caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c227a3",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77eabdd9d90479899bf150d4485450c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>sess_idx</th>\n",
       "      <th>sess_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>720244</td>\n",
       "      <td>20.0</td>\n",
       "      <td>131827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1089016</td>\n",
       "      <td>24.0</td>\n",
       "      <td>64001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1901922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>504314</td>\n",
       "      <td>26.0</td>\n",
       "      <td>47244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510501</td>\n",
       "      <td>38.0</td>\n",
       "      <td>43696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>691208</td>\n",
       "      <td>9.0</td>\n",
       "      <td>43345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25325</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>486806</td>\n",
       "      <td>27.0</td>\n",
       "      <td>36692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1476553</td>\n",
       "      <td>58.0</td>\n",
       "      <td>30282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6822632</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1645005</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1078272</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>441374</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>755122</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>496635</td>\n",
       "      <td>45.0</td>\n",
       "      <td>22672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6880242</td>\n",
       "      <td>43.0</td>\n",
       "      <td>22564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>516624</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>755122</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1578544</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5079737</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  sess_idx  sess_len\n",
       "0    720244      20.0    131827\n",
       "1   1089016      24.0     64001\n",
       "2   1901922       1.0     48775\n",
       "3    504314      26.0     47244\n",
       "4    510501      38.0     43696\n",
       "5    691208       9.0     43345\n",
       "6     25325       1.0     42071\n",
       "7    486806      27.0     36692\n",
       "8   1476553      58.0     30282\n",
       "9   6822632      13.0     27301\n",
       "10  1645005       7.0     27079\n",
       "11  1078272       6.0     26259\n",
       "12   441374       5.0     25347\n",
       "13   755122      17.0     25170\n",
       "14   496635      45.0     22672\n",
       "15  6880242      43.0     22564\n",
       "16   516624      24.0     22201\n",
       "17   755122      20.0     21938\n",
       "18  1578544       5.0     21138\n",
       "19  5079737       6.0     20498"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [CELL 01-15] Inspect session length outliers (top 20)\n",
    "\n",
    "gap_minutes = 30\n",
    "\n",
    "df_top = con.execute(f\"\"\"\n",
    "WITH x AS (\n",
    "  SELECT\n",
    "    user_id,\n",
    "    item_id,\n",
    "    ts,\n",
    "    LAG(ts) OVER (PARTITION BY user_id ORDER BY ts) AS prev_ts\n",
    "  FROM inter\n",
    "),\n",
    "y AS (\n",
    "  SELECT\n",
    "    user_id,\n",
    "    item_id,\n",
    "    ts,\n",
    "    CASE\n",
    "      WHEN prev_ts IS NULL THEN 1\n",
    "      WHEN ts - prev_ts > INTERVAL '{gap_minutes} minutes' THEN 1\n",
    "      ELSE 0\n",
    "    END AS new_sess\n",
    "  FROM x\n",
    "),\n",
    "z AS (\n",
    "  SELECT\n",
    "    user_id,\n",
    "    item_id,\n",
    "    ts,\n",
    "    SUM(new_sess) OVER (PARTITION BY user_id ORDER BY ts ROWS UNBOUNDED PRECEDING) AS sess_idx\n",
    "  FROM y\n",
    "),\n",
    "sizes AS (\n",
    "  SELECT user_id, sess_idx, COUNT(*) AS sess_len\n",
    "  FROM z\n",
    "  GROUP BY user_id, sess_idx\n",
    ")\n",
    "SELECT * FROM sizes\n",
    "ORDER BY sess_len DESC\n",
    "LIMIT 20;\n",
    "\"\"\").df()\n",
    "\n",
    "display(df_top)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6d6d7",
   "metadata": {},
   "source": [
    "Build session-level course sequences (dedupe course repeats within session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1768079e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1885da013e5a4079b1052203d8208594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_events</th>\n",
       "      <th>n_sessions</th>\n",
       "      <th>q_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6350920</td>\n",
       "      <td>6350920</td>\n",
       "      <td>[1, 3, 12]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_events  n_sessions       q_len\n",
       "0   6350920     6350920  [1, 3, 12]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [CELL 01-16] Build session-level sequences (course-level), dedup consecutive repeats\n",
    "\n",
    "gap_minutes = 30\n",
    "MAX_EVENTS_PER_SESSION = 500\n",
    "\n",
    "# Create a \"sessioned events\" view with session ids\n",
    "con.execute(f\"\"\"\n",
    "CREATE OR REPLACE VIEW sessioned AS\n",
    "WITH x AS (\n",
    "  SELECT\n",
    "    user_id,\n",
    "    item_id,\n",
    "    ts,\n",
    "    LAG(ts) OVER (PARTITION BY user_id ORDER BY ts) AS prev_ts\n",
    "  FROM inter\n",
    "),\n",
    "y AS (\n",
    "  SELECT\n",
    "    user_id,\n",
    "    item_id,\n",
    "    ts,\n",
    "    CASE\n",
    "      WHEN prev_ts IS NULL THEN 1\n",
    "      WHEN ts - prev_ts > INTERVAL '{gap_minutes} minutes' THEN 1\n",
    "      ELSE 0\n",
    "    END AS new_sess\n",
    "  FROM x\n",
    "),\n",
    "z AS (\n",
    "  SELECT\n",
    "    user_id,\n",
    "    item_id,\n",
    "    ts,\n",
    "    SUM(new_sess) OVER (PARTITION BY user_id ORDER BY ts ROWS UNBOUNDED PRECEDING) AS sess_idx\n",
    "  FROM y\n",
    "),\n",
    "ranked AS (\n",
    "  SELECT\n",
    "    user_id,\n",
    "    sess_idx,\n",
    "    item_id,\n",
    "    ts,\n",
    "    ROW_NUMBER() OVER (PARTITION BY user_id, sess_idx ORDER BY ts) AS rn,\n",
    "    LAG(item_id) OVER (PARTITION BY user_id, sess_idx ORDER BY ts) AS prev_item\n",
    "  FROM z\n",
    "),\n",
    "trimmed AS (\n",
    "  SELECT *\n",
    "  FROM ranked\n",
    "  WHERE rn <= {MAX_EVENTS_PER_SESSION}\n",
    "),\n",
    "dedup AS (\n",
    "  SELECT *\n",
    "  FROM trimmed\n",
    "  WHERE prev_item IS NULL OR item_id <> prev_item\n",
    ")\n",
    "SELECT\n",
    "  user_id,\n",
    "  sess_idx,\n",
    "  item_id,\n",
    "  ts\n",
    "FROM dedup;\n",
    "\"\"\")\n",
    "\n",
    "# Session lengths after trimming+dedup\n",
    "df_len = con.execute(\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS n_events,\n",
    "  COUNT(DISTINCT user_id || '-' || sess_idx) AS n_sessions,\n",
    "  approx_quantile(cnt, [0.5,0.9,0.99]) AS q_len\n",
    "FROM (\n",
    "  SELECT user_id, sess_idx, COUNT(*) cnt\n",
    "  FROM sessioned\n",
    "  GROUP BY user_id, sess_idx\n",
    ");\n",
    "\"\"\").df()\n",
    "display(df_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c0bc01",
   "metadata": {},
   "source": [
    "Export final session dataset for modeling notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "70a2c175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5bdfb093719495d8d4eb22a78326d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] 2025-12-29 01:24:23 | Wrote: D:\\00_DS-ML-Workspace\\mooc-coldstart-session-meta\\data\\processed\\xuetangx_sessions_course.parquet\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-17] Export sessioned sequences to Parquet\n",
    "\n",
    "OUT_SESS = (REPO_ROOT / \"data\" / \"processed\" / \"xuetangx_sessions_course.parquet\").resolve()\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "COPY (\n",
    "  SELECT\n",
    "    user_id,\n",
    "    CAST(sess_idx AS INTEGER) AS session_idx,\n",
    "    item_id,\n",
    "    ts\n",
    "  FROM sessioned\n",
    ") TO '{str(OUT_SESS)}' (FORMAT PARQUET);\n",
    "\"\"\")\n",
    "\n",
    "log(f\"Wrote: {OUT_SESS}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
